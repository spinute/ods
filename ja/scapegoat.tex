\chapter{Scapegoat Tree}
\chaplabel{scapegoat}

この章では二分探索木の一種である#ScapegoatTree#を紹介する。
このデータ構造は何か誤りがあるとき、それは誰の責任なのかを決めようとする現実でよくある考え方に基づく。（scapegoatとは罪を負わされたヤギ、転じて身代わりのことである。）
\ejindex{scapegoat}{スケープゴート}%
責任の所在が決まれば、そいつに問題を解決させることができる。

#ScapegoatTree#は\emph{部分的な再構築}によってバランスを保つ。
\ejindex{partial rebuilding}{ぶぶんてきなさいこうちく@部分的な再構築}%
\ejindex{binary search tree!partial rebuilding}{にぶんたんさくぎ@二分探索木!ぶぶんてきなさいこうちく@部分的な再構築}%
部分再構築の間に、ある部分木全体が分解され完全にバランスされた部分木として再構築される。
ノード#u#を根とする部分木を完全にバランスされた木に再構築するやり方はたくさんある。
もっとも単純なやり方のひとつは#u#の部分木を辿りすべてのノードを配列#a#に集め、#a#から再帰的にバランスされた木を構築するものだ。
$#m#=#a.length#/2$とするとき、#a[m]#を新たな部分木の根とし、$#a#[0],\ldots,#a#[#m#-1]$は左の部分木に、$#a#[#m#+1],\ldots,#a#[#a.length#-1]$は右の部分木にそれぞれ再帰的に格納される。
\codeimport{ods/ScapegoatTree.rebuild(u).packIntoArray(u,a,i).buildBalanced(a,i,ns)}
#rebuild(u)#の実行時間は$O(#size(u)#)$である。
結果として得られる部分木は高さ最小のものである。
すなわち、#size(u)#個のノードを持ちこの木より低い木は存在しない。

\section{#ScapegoatTree#：部分再構築する二分探索木}
\seclabel{scapegoattree}

\index{ScapegoatTree@#ScapegoatTree#}%
#ScapegoatTree#とは、#BinarySearchTree#であり、ノード数#n#に加えてノード数の上界を保持する#q#を持つ。
\codeimport{ods/ScapegoatTree.q}
#n#と#q#は常に次の式を満たす。
\[
      #q#/2 \le  #n# \le #q#
\]
加えて#ScapegoatTree#の高さは対数程度である。
すなわちscapegoat treeの高さは常に次の値以下である。
\begin{equation}
     \log_{3/2} #q# \le \log_{3/2} 2#n# < \log_{3/2} #n# + 2
     \eqlabel{scapegoat-height}
\end{equation}
この制約を満たしても、#ScapegoatTree#は意外と偏って見た目になりうる。
例えば\figref{scapegoat-example}は$#q#=#n#=10$であり、高さ$5<\log_{3/2}10 \approx 5.679$の木である。

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/scapegoat-insert-1}
  \end{center}
  \caption{10個のノードを持ち、高さが5である#ScapegoatTree#の例}
  \figlabel{scapegoat-example}
\end{figure}

#ScapegoatTree#における#find(x)#の実装は#BinarySearchTree#の場合の標準的なものを使う。（\secref{binarysearchtree}を参照せよ。）
実行時間は木の高さに比例し、\myeqref{scapegoat-height}よりこれは$O(\log #n#)$である。

#add(x)#の実装では、まず#n#と#q#をひとつずつ増やし、#x#を二分探索木に追加するふつうのアルゴリズムを使う。
すなわち、#x#を探し、新たな葉#u#を追加し、$#u.x#=#x#$とする。
このとき、運良く#u#の深さが$\log_{3/2}#q#$以下なら、これ以上なにもしなくてよい。

$#depth(u)# > \log_{3/2} #q#$であることもある。
この場合、高さを減らす必要がある。
これはそんなに大変ではない。
今、ノード#u#だけが、木の中で深さが$\log_{3/2} #q#$を超えているノードである。
#u#を修正するために、木を上に向かって辿りながら\emph{scapegoat}であるノード#w#を探す。
#w#は非常にバランスの悪いノードである。
ここでバランスは次の式で判断される。
\begin{equation}
   \frac{#size(w.child)#}{#size(w)#} > \frac{2}{3}
   \eqlabel{scapegoat}
\end{equation}
#w.child#は#w#の子であって、根から#u#に至る経路上にあるものである。
scapegoatが存在することを示すのは難しくない。
今はこれを事実として認めることにする。
scapegoat #w#が見つかれば#w#を根とする部分木を完全に取り壊し、完全にバランスされた二分探索木として再構築すればよい。
\myeqref{scapegoat}より、#u#を加える前から#w#の部分木は完全二分木ではない。
よって、#w#を再構築するときにその高さは1以上減り、#ScapegoatTree#の高さは再度$\log_{3/2}#q#$以上になる。

\codeimport{ods/ScapegoatTree.add(x)}

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[scale=0.90909]{figs/scapegoat-insert-3} &
      \includegraphics[scale=0.90909]{figs/scapegoat-insert-4}
    \end{tabular}
  \end{center}
  \caption{#ScapegoatTree#に3.5を追加する。このとき木の高さは6に増え、$6 > \log_{3/2} 11 \approx 5.914$より\myeqref{scapegoat-height}が成り立たない。scapegoatは値5を含むノードで見つかる。}
\end{figure}
scapegoat #w#を見つけるコスト、#w#を根とする部分木を再構築するコストを無視すれば、#add(x)#の実行時間のうち支配的なのは最初の検索のものであり、これは$O(\log #q#) = O(\log #n#)$である。
scapegoatを見つけ、部分木を再構築するコストは、次小節で償却解析を使って説明する。

#ScapegoatTree#における#remove(x)#の実装は非常に単純である。
#x#を探し、#BinarySearchTree#におけるアルゴリズムを使ってそれを削除する。
（これは木の高さを増やすことはない。）
そして#n#をひとつ小さくし、#q#はそのままにしておく。
最後に$#q# > 2#n#$かどうかを確認し、もしそうなら\emph{木全体を再構築}し、完全にバランスされた二分探索木にして、$#q#=#n#$とする。
\codeimport{ods/ScapegoatTree.remove(x)}
ここでも、再構築のコストを無視すれば、#remove(x)#の実行時間は木の高さに比例し、$O(\log #n#)$である。

\subsection{正しさの証明と実行時間の解析}

ここでは#ScapegoatTree#の各操作の正しさと償却実行時間の解析とを行う。
まずは正しさを示すために、#add(x)#操作において\myeqref{scapegoat-height}が成り立たなくなったなら常にscapegoatを見つけられることを示す。

\begin{lem}
  #u#を#ScapegoatTree#における深さ$h>\log_{3/2} #q#$のあるノードとする。
  このとき#u#からrootへの経路上に次の条件を満たすノード#w#が存在する。
  \[
     \frac{#size(w)#}{#size(parent(w))#} > 2/3
  \]
\end{lem}

\begin{proof}
背理法で示す。
#u#からrootへの経路上の任意のノード#w#について次の式が成り立つと仮定する。
\[
   \frac{#size(w)#}{#size(parent(w))#} \le 2/3
\]
また、根から#u#への経路を$#r#=#u#_0,\ldots,#u#_h=#u#$とする。
このとき
$#size(u#_0#)#=#n#$、
$#size(u#_1#)#\le\frac{2}{3}#n#$、
$#size(u#_2#)#\le\frac{4}{9}#n#$であり、より一般に次の式が成り立つ。
\[
#size(u#_i#)#\le\left(\frac{2}{3}\right)^i#n#
\]
ここで$#size(u)#\ge 1$より次の式が成り立つことを示す。
\[
    1 \le #size(u)# \le \left(\frac{2}{3}\right)^h#n#
   < \left(\frac{2}{3}\right)^{\log_{3/2} #q#}#n#
   \le \left(\frac{2}{3}\right)^{\log_{3/2} #n#}#n#
   = \left(\frac{1}{#n#}\right) #n#
   = 1  \qedhere
\]
しかしこれは成り立たず、矛盾が導かれた。
\end{proof}

続いてまだ説明していない部分の実行時間の解析を行う。
scapegoatノードを探す際の#size(u)#・#rebuild(w)#のコストを改正する。
これらふたつの操作の間には次のような関係がある。
\begin{lem}
#ScapegoatTree#の#add(x)#において、scapegoat #w#を見つけて#w#を根とする部分木を再構築するコストは$O(#size(w)#)$である。
\end{lem}

\begin{proof}
scapegoatノード#w#を見つけたあと、そこから再構築を行うコストは$O(#size(w)#)$である。
scapegoatを見つけるためには#size(u)#を$#u#_k=#w#$を見つけるまで$#u#_0,\ldots,#u#_k$に順に実行する。
しかし、 $#u#_k$はこの列における最初のscapegoatノードなので、任意の$i\in\{0,\ldots,k-2\}$について次の式が成り立つ。
\[
  #size(u#_{i}#)# < \frac{2}{3}#size(u#_{i+1}#)#
\]
よって、すべての#size(u)#呼び出しのコストの合計は次のようになる。
\begin{eqnarray*}
 O\left( \sum_{i=0}^k #size(u#_{k-i}#)# \right)
 &=& O\left(
  #size(u#_k#)#
  + \sum_{i=0}^{k-1} #size(u#_{k-i-1}#)#
  \right) \\
 &=& O\left(
  #size(u#_k#)#
  + \sum_{i=0}^{k-1} \left(\frac{2}{3}\right)^i#size(u#_{k}#)#
  \right) \\
&=& O\left(
  #size(u#_k#)#\left(1+
   \sum_{i=0}^{k-1} \left(\frac{2}{3}\right)^i
  \right)\right) \\
&=& O(#size(u#_k#)#) = O(#size(w)#)
\end{eqnarray*}
最後の行は減少幾何数列の和を計算している。
\end{proof}

最後に、$m$個の操作を順に実行する時の#rebuild(u)#の合計コストの上界を示す。

\begin{lem}\lemlabel{scapegoat-amortized}
空の#ScapegoatTree#に対して、$m$個の#add(x)#・#remove(x)#からなる操作の列を順に実行するとき、#rebuild(u)#に要する時間の合計は$O(m\log m)$である。
\end{lem}

\begin{proof}
XXX: credit schemeの訳語は? accounting method（AlgoIntroでは出納法）のことだろうか?

\emph{credit scheme}を使って示す。
\index{credit scheme}%
各ノードは預金を持っていると考える。
預金が$c$だけあれば再構築のための支払いができる。
預金の合計は$O(m\log m)$で、#rebuild(u)#は#u#に蓄えられている預金を使って支払われる。

挿入・削除の際に挿入・削除されるノード#u#への経路上にある各ノードの預金を1だけ増やす。
こうして一回の操作で増える預金の合計は最大$\log_{3/2}#q#\le \log_{3/2}m$である。
削除の際には多めに預金を蓄えることになる。
こうして最大$O(m\log m)$だけの預金を行う。
あとは、これだけの預金ですべての#rebuild(u)#の支払いに十分であることを示せばよい。

挿入の際に#rebuild(u)#を実行するなら、#u#はscapegoatである。
次のことを仮定しても一般性を失わない。
\[
\frac{#size(u.left)#}{#size(u)#} > \frac{2}{3}
\]
次の事実を仮定すると、
  \[
    #size(u)# = 1 + #size(u.left)# + #size(u.right)#
  \]
  次の式が成り立つ。
  \[
    \frac{1}{2}#size(u.left)# > #size(u.right)#
  \]
このとき、さらに次の式が成り立つ。
  \[
    #size(u.left)# - #size(u.right)# > \frac{1}{2}#size(u.left)# >
    \frac{1}{3}#size(u)#
  \]
#u#を含む部分木が直前に再構築されたとき（もし、#u#を含む部分木が一度も再構築されていなければ、#u#が挿入されたとき）、次の式が成り立つ。
  \[
    #size(u.left)# - #size(u.right)# \le 1
  \]
よって、#u.left#・#u.right#に影響を与えた#add(x)#・#remove(x)#の数の合計は次の値以上である。
  \[
    \frac{1}{3}#size(u)# - 1
  \]
#u#には少なくともこれだけの預金が蓄えられており、#rebuild(u)#に必要な$O(#size(u)#)$だけの支払いには十分である。

削除において#rebuild(u)#が呼ばれるとき、$#q# > 2#n#$である。
この場合、$#q#-#n#> #n#$だけ余分に預金が蓄えられており、根の再構築に必要な$O(#n#)$だけの支払いには十分である。

以上で示された。
\end{proof}

\subsection{要約}
次の定理は#ScapegoatTree#の性能をまとめるものだ。

\begin{thm}\thmlabel{scapegoat}
  #ScapegoatTree#は#SSet#インターフェースを実装する。
  #rebuild(u)#のコストを無視すると、#ScapegoatTree#は#add(x)#・#remove(x)#・#find(x)#をいずれも$O(\log #n#)$の時間で実行できる。
  さらに、空の#ScapegoatTree#に対して、$m$個の#add(x)#・#remove(x)#からなる操作の列を順に実行するとき、#rebuild(u)#に要する時間の合計は$O(m\log m)$である。
\end{thm}

\section{ディスカッションと練習問題}

GalperinとRivest\cite{gr93}が\emph{scapegoat tree}という名前を提案し、このデータ構造を定義し、解析した。
しかし同じデータ構造がAndersson \cite{a89,a99}によって先に発見されており、そこでは
\index{general balanced tree}%
\emph{general balanced trees}
と呼ばれていた。
これはこのデータ構造は高さが小さいならどのような形状も取れることによる。

#ScapegoatTree#の実装で実験してみると、この本で紹介した他の#SSet#の実装と比べてかなり遅いことがわかる。
高さの上界は
\[
   \log_{3/2}#q# \approx 1.709\log #n# + O(1)
\]
であり、これは#Skiplist#の探索経路の長さの期待値よりも良く、#Treap#とも遠くないため、この結果は意外かもしれない。
最適化として、部分木のサイズを各ノードが保持したり、既に計算した部分木のサイズを再利用したりできる。
（\ref{exc:scapegoat-quicksize}と\ref{exc:scapegoat-explicitsize}を参照せよ。）
これらの最適化をしても依然として#add(x)#・#delete(x)#からなる操作の列を#ScapegoatTree#で実行したとき、他の#SSet#の実装より遅いことがあるだろう。

この本で扱った他の#SSet#の実装と異なり#ScapegoatTree#は再構築自体に多くの時間を消費するため、このような性能差が現れる。
この本で紹介した他の#SSet#の実装では、#n#個の操作の間に$O(#n#)$程度のデータ構造の変形をすればよかった。
一方、\excref{scapegoat-nlogn}から#n#個の操作の列を#ScapegoatTree#に実行するとき、$#n#\log #n#$のオーダーの時間を#rebuild(u)#に費やすことがわかる。
これは再構築をすべて#rebuild(u)#で行っていることの帰結である。 \cite{d90}.

性能は劣るものの、#ScapegoatTree#を使うのが正しい選択となる場合がある。
これは、各ノードに追加のデータがあり、それを回転操作においては定数時間で更新できないが、#rebuild(u)#操作の際に更新できる場合である。
この場合#ScapegoatTree#や部分的な再構築を行う他のデータ構造が有効である。
このような応用の例を\excref{list-order-maintenance}で取り上げている。

\begin{exc}
  \figref{scapegoat-example}の#ScapegoatTree#に1.5、1.6を順に追加する様子を描け。
\end{exc}

\begin{exc}
  空の#ScapegoatTree#に$1,5,2,4,3$を順に追加する様子を描け。
  加えて、\lemref{scapegoat-amortized}の証明で使った預金がどう移動し、どのように使われるかも説明せよ。
\end{exc}

\begin{exc}\exclabel{scapegoat-nlogn}
  空の#ScapegoatTree#に対して、$#x#=1,2,3,\ldots,#n#$について順に#add(x)#を呼び出す。
  このときある定数$c>0$が存在し、#rebuild(u)#に要する時間の合計は$c#n#\log #n#$以上であることを示せ。
\end{exc}

\begin{exc}
  #ScapegoatTree#における探索経路の長さは$\log_{3/2}#q#$を超えない。
  \begin{enumerate}
    \item #ScapegoatTree#を修正し、$1<#b#<2$を満たすパラメータ#b#について探索経路の長さが$\log_{#b#} #q#$を超えないデータ構造を、設計・解析・実装せよ。
    \item 解析・実験によると、#find(x)#・#add(x)#・#remove(x)#の償却コストは#n#と#b#の関数としてどう表せるか。
  \end{enumerate}
\end{exc}

\begin{exc}\exclabel{scapegoat-quicksize}
  #ScapegoatTree#の#add(x)#メソッドを修正し、既に計算した部分木の大きさは再計算せず、無駄を省くように修正せよ。
  #size(w)#を計算するとき、#size(w.left)#か#size(w.right)#は既に計算しているため、このような最適化が可能である。
  修正前後での性能を比較せよ。
\end{exc}

\begin{exc}\exclabel{scapegoat-explicitsize}
  #ScapegoatTree#の変種として、明示的に各ノードを根とする部分木の大きさを蓄えるものを実装せよ。
  もともとの#ScapegoatTree#や\excref{scapegoat-quicksize}での実装と、ここでの実装とを性能比較せよ。
\end{exc}

\begin{exc}
  この章の最初に説明した#rebuild(u)#を、再構築する部分木に含まれるノードを蓄える配列を使わずに再実装せよ。
  代わりに、まずは再帰を使ってこれらのノードを連結リストにし、この連結リストを完全にバランスされた二分木に変換せよ。
  （いずれのステップにも華麗な再帰による実装がある。）
\end{exc}

\begin{exc}
  \index{WeightBalancedTree@#WeightBalancedTree#}%
  #WeightBalancedTree#を設計・実装せよ。
  このデータ構造では、根以外の各ノード#u#は\emph{バランス条件}$#size(u)# \le (2/3)#size(u.parent)#$を満たす。
  #add(x)#・#remove(x)#操作はふつうの#BinarySearchTree#とほぼ同じだが、ノード#u#でバランス条件が成り立たないときには#u.parent#を根とする部分木が再構築される点でのみ異なっている。
  そして、#WeightBalancedTree#の償却実行時間は$O(\log#n#)$であることを示せ。
\end{exc}

\begin{exc}
  \index{CountdownTree@#CountdownTree#}%
  #CountdownTree#を設計・実装せよ。
  このデータ構造では各ノード#u#は\emph{タイマー} #u.t#を持っている。
  #add(x)#・#remove(x)#操作はふつうの#BinarySearchTree#とほぼ同じだが、いずれかの操作が#u#の部分木に影響を与えるとき、#u.t#をひとつ小さくする点で異なる。
  $#u.t#=0$のとき、#u#を根とする部分木は完全にバランスされた二分木に再構築される。
  ノード#u#が再構築に関わるとき（#u#が再構築されるか、#u#の祖先のうちのひとつが再構築されるとき）#u.t#は$#size(u)#/3$にリセットされる。

  そして、#CountdownTree#の償却実行時間は$O(\log#n#)$であることを示せ。
  （ヒント：まずは任意のノードがあるバランスに関する不変条件を満たすことを示せ。）
\end{exc}

\begin{exc}
  \index{DynamiteTree@#DynamiteTree#}%
  #DynamiteTree#を設計・実装せよ。
  このデータ構造ではすべてのノード#u#は#u#を根とする部分着の大きさを#u.size#として保持する。
  #add(x)#・#remove(x)#操作はふつうの#BinarySearchTree#とほぼ同じだが、
  いずれかの操作が#u#の部分木に影響を与えるとき、#u#は確率$1/#u.size#$で\emph{爆発}する。
  #u#が爆発すると、#u#を根とする部分木は完全にバランスされた二分木に再構築される。

  そして、#DynamiteTree#の償却実行時間は$O(\log#n#)$であることを示せ。
\end{exc}

\begin{exc}\exclabel{list-order-maintenance}
  \index{Sequence@#Sequence#}%
  要素の列を保持するデータ構造#Sequence#を設計・実装せよ。
  これは次のような操作を提供する。
  \begin{itemize}
    \item #addAfter(e)#：要素#e#の次に新たな要素を追加する。
	また、新たに追加した要素を返す。
	（#e#が#null#なら新たな要素は列の先頭に追加される。）
    \item #remove(e)#：#e#を列から削除する。
    \item #testBefore(e1,e2)#：#e1#が#e2#の前にあるならば、またそのときに限って#true#を返す。
  \end{itemize}
  はじめのふたつの操作の償却実行時間は$O(\log #n#)$でなければならない。
  みっつめの操作は定数時間でなければならない。

  #Sequence#は、列の中の順序を使い、#ScapegoatTree#のようにデータを蓄えれば実装できる。
  #testBefore(e1,e2)#を定数時間で実装するために、要素#e#は根から#e#への経路を符号化した整数でラベル付けされる。
  こうすると#testBefore(e1,e2)#は#e1#と#e2#のラベルを比較すればよい。
\end{exc}
