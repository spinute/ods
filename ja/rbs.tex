\chapter{ランダム二分探索木}
\chaplabel{rbs}

この章では、乱択化を使って各操作について$O(\log #n#)$の実行時間を達成する二分探索木を紹介する。%ランダム化？乱択化？ -kshikano

\section{ランダム二分探索木}
\seclabel{rbst}

\figref{rbs-lvc}に示した2つの二分探索木を見てほしい。
これらはいずれも$#n#=15$個のノードからなる。
左の木はリストであり、右の木は完全にバランスされた二分探索木である。
左の木の高さは$#n#-1=14$で、右の木の高さは3である。

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[scale=0.90909,scale=0.95]{figs/bst-path} &
      \includegraphics[scale=0.90909,scale=0.95]{figs/bst-balanced}
    \end{tabular}
  \end{center}
  \caption{$0,\ldots,14$からなる2つの二分探索木}
  \figlabel{rbs-lvc}
\end{figure}

この2つの木の構築方法を考えてみよう。
空の#BinarySearchTree#に対して、次の順で要素を追加すると、左の木になる。
\[
    \langle 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14 \rangle
\]
逆に、左の木になるような要素の追加順は、この順に限る（#n#についての帰納法で証明できる）。
一方、次の順で要素を追加すると、右の木になる。
\[
    \langle 7,3,11,1,5,9,13,0,2,4,6,8,10,12,14 \rangle
\]
右の木は、ほかにも次のような追加順で得られる。
\[
    \langle 7,3,1,5,0,2,4,6,11,9,13,8,10,12,14 \rangle\\
\]
\[
    \langle 7,3,1,11,5,0,2,4,6,9,13,8,10,12,14 \rangle
\]
実際、右の木が得られるような要素の追加順は、全部で$21,964,800$種類ある。その一方で、左の木が得られるような要素の追加順はたった1つしかない。

% YJ: Anecdotal evidenceは信頼性の低い、事例を元にした証拠という意味。定性的というのは必ずしも信頼性の低さを意味するものではないと思う(定性的だが信頼性の高い証拠も考えられる)。対応する日本語はあまりないがこの場合一番近い日常語は直感的とかだと思う。/ よく使うのは傍証という訳語ですが、ここは現訳のほうがよさそうです（ただ、読みにくいので二文に分けました）。 -kshikano
この例からは次のようなことがいえるだろう。すなわち、$0,\ldots,14$をランダムな順番で選んで二分探索木に追加すれば、多くの場合は\figref{rbs-lvc}の右に示すようなバランスされた木になり、左に示すような極めて偏った木になることはあまりなさそうである。

この主張は、ランダム二分探索木を考えることで形式的に説明できる。
まずは大きさ#n#の\emph{ランダム二分探索木（random binary search tree）}の作り方を述べる。
\ejindex{random binary search tree}{らんだむにぶんたんさくぎ@ランダム二分探索木}%
\ejindex{binary search tree!random}{にぶんたんさくぎ@二分探索木!ランダム}%

$0,\ldots,#n#-1$のランダムな置換を1つ選ぶ。
これを$#x#_0,\ldots,#x#_{#n#-1}$とし、この順番に要素を#BinarySearchTree#に追加する。
ここで、\emph{ランダムな置換（random permutation）}
\ejindex{permutation!random}{ちかん@置換!らんだむ@ランダム}%
\ejindex{random permutation}{らんだむなちかん@ランダムな置換}%
とは、全部で$#n#!$通りある$0,\ldots,#n#-1$の置換はそれぞれ等確率$1/#n#!$で選び出せるので、そのうちの1つを選んだものである。

$0,\ldots,#n#-1$は、#n#個の値であればなんでもよいことに注意してほしい。別の値であってもランダム二分探索木の性質には影響しない。
$#x#\in\{0,\ldots,#n#-1\}$は、順序が定義された#n#個の要素からなる集合における#x#番めの要素を表しているにすぎない。

ランダム二分探索木の性質を説明する前に、少し脱線して、ランダムな構造を解析する際にしばしば登場する\emph{調和数（harmonic number）}について説明しよう。
$k$を非負整数とすると、$k$番めの調和数$H_k$は次のように定義される。
\ejindex{harmonic number}{ちょうわすう@調和数}%
\index{H@$H_k$ (harmonic number)}%
\[
  H_k = 1 + 1/2 + 1/3 + \cdots + 1/k
\]
調和数$H_k$は単純な閉じた式では書けないが、自然対数と密接な関係があり、次の式が成り立つ。
\[
  \ln k < H_k \le \ln k + 1
\]
\newcommand{\hint}{\int_1^k\! (1/x)\, \mathrm{d}x}%
解析学を学んでいれば、$\hint = \ln k$からこれを示せるだろう。
積分は、曲線と$x$軸とが囲む領域の面積と解釈できるので、$H_k$の下界は$\hint$、上界は$1+ \hint$である
（\figref{harmonic-integral}を見れば視覚的に理解できるだろう）。

\begin{figure}
  \begin{center}
    \begin{tabular}{cc}
      \includegraphics[width=\HalfScaleIfNeeded]{figs/harmonic-2}
        & \includegraphics[width=\HalfScaleIfNeeded]{figs/harmonic-3}
    \end{tabular}
  \end{center}
  \caption{$k$番めの調和数$H_k=\sum_{i=1}^k 1/i$の上界、下界を積分で計算できる。各積分値は図の斜線部の面積であり、$H_k$は長方形の部分の面積である。}
  \figlabel{harmonic-integral}
\end{figure}

\begin{lem}\lemlabel{rbs}
大きさ#n#のランダム二分探索木について以下が成り立つ。
  \begin{enumerate}
    \item 任意の$#x#\in\{0,\ldots,#n#-1\}$について、#x#を探すときの探索経路の長さの期待値は$H_{#x#+1} + H_{#n#-#x#} - 2$である\footnote{$#x#+1$と$#n#-#x#$は#x#以上の要素の個数、#x#以下の要素の個数と解釈できる。}。 % 原著では - 2 ではなく - O(1) になっている。しかし、次の小節では#x#の探索経路の長さの期待値は$H_{#x#+1} + H_{#n#-#x#} - 2$であることを証明しており、またこの節の最後の文の根拠としても、ここは - 2 とした方が適切そうである。
    \item 任意の$#x#\in(-1,n)\setminus\{0,\ldots,#n#-1\}$について、#x#を探すときの探索経路の長さの期待値は$H_{\lceil#x#\rceil} + H_{#n#-\lceil#x#\rceil}$である。
  \end{enumerate}
\end{lem}

\lemref{rbs}の証明は次項で行う。
ここでは\lemref{rbs}の意味を考える。
1つめの主張は、木に含まれる要素を探す場合、木の要素数を#n#とすると、探索経路の長さの期待値は$2\ln #n# + O(1)$以下であるというものだ。
2つめの主張は、木に含まれない要素を探す場合について、やはり探索経路の長さの期待値に関する評価を与えている。 % YJ removed ambiguousity
これらを比べると、木に含まれない要素を探すより、含まれる要素を探すほうが少しだけ速いことがわかる。

\subsection{\lemref{rbs}の証明}

\lemref{rbs}の証明では次の考察が鍵となる。
ランダム二分探索木$T$における値$#x# \in (-1,#n#)$の探索経路に、$i < #x#$を満たす#i#をキーとするノードが含まれる必要十分条件は、$T$を作るランダムな置換において$i$が$\{i+1,i+2,\ldots,\lfloor#x#\rfloor\}$のいずれよりも前に現れることである。

そのことを確認するには、\figref{rbst-records}を見てほしい。
$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$のいずれかが追加されるまで、探索経路$(i-1,\lfloor#x#\rfloor+1)$に含まれる要素の探索経路は等しい
（2つの要素の探索経路が別々になるためには、一方以上かつ他方以下の要素がなければならないことを思い出そう）。
ランダムな置換において最初に現れる$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$の要素を$j$とする。
$j$は、#x#の探索経路上にずっと存在していることに注意しよう。
$j\neq i$ならば、$j$を含むノード$#u#_j$は、$i$を含むノード$#u#_i$より先に作られる。
そのあとで$i$を追加するときは、$i<j$なので、$#u#_j#.left#$を根とする部分木に$#u#_i$が追加される。
一方、#x#の探索経路は、この部分木を通らない。
なぜなら、この経路は$#u#_j$を訪問したあと、$#u#_j#.right#$に向かうからである。

\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/rbst-records}
  \end{center}
  \caption{値$i<#x#$が#x#の探索経路中にあることの必要十分条件は$i$が$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$のうち最初に木に加えられた要素であることである。}
  \figlabel{rbst-records}
\end{figure}

$i>#x#$の場合も、キー$i$が#x#の探索経路に含まれる必要十分条件は、$T$を作るランダムな置換において、$i$が$\{\lceil#x#\rceil, \lceil#x#\rceil+1,\ldots,i-1\}$のいずれよりも前に現れることである。

$\{0,\ldots,#n#\}$のランダムな置換では、そのうちの一部だけを取り出した部分列$\{i,i+1,\ldots,\lfloor#x#\rfloor\}$および$\{\lceil#x#\rceil, \lceil#x#\rceil+1,\ldots,i-1\}$も、やはりそれぞれ対応する要素からなる列のランダムな置換になっている。
このとき、$T$を作るランダムな置換において、どちらの部分列でも先頭には各要素が等しい確率で現れる。そのため次の式が得られる。
\[
  \Pr\{\mbox{$i$が#x#の探索経路に含まれる}\}
  = \left\{ \begin{array}{ll}
     1/(\lfloor#x#\rfloor-i+1) & \mbox{if $i < #x#$} \\
     1/(i-\lceil#x#\rceil+1) & \mbox{if $i > #x#$}
     \end{array}\right . \enspace .
\]

以上の考察により、調和数を使った簡単な計算で\lemref{rbs}を証明できる。

\begin{proof}[\lemref{rbs}の証明]
$I_i$をインジケータ確率変数とする。
$I_i$の値は、$i$が探索経路に現れるときは1、そうでないときは0である。
このとき探索経路の長さを次のように計算できる。
\[
  \sum_{i\in\{0,\ldots,#n#-1\}\setminus\{#x#\}} I_i
\]
よって、$#x#\in\{0,\ldots,#n#-1\}$なら探索経路の長さの期待値は次のように計算できる（\figref{rbst-probs}(a)参照）。
\begin{align*}
  \E\left[\sum_{i=0}^{#x#-1} I_i + \sum_{i=#x#+1}^{#n#-1} I_i\right]
   & =  \sum_{i=0}^{#x#-1} \E\left[I_i\right]
         + \sum_{i=#x#+1}^{#n#-1} \E\left[I_i\right] \\
   & = \sum_{i=0}^{#x#-1} 1/(\lfloor#x#\rfloor-i+1)
         + \sum_{i=#x#+1}^{#n#-1} 1/(i-\lceil#x#\rceil+1) \\
   & = \sum_{i=0}^{#x#-1} 1/(#x#-i+1)
         + \sum_{i=#x#+1}^{#n#-1} 1/(i-#x#+1) \\
   & = \frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{#x#+1} \\
   & \quad {} + \frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{#n#-#x#} \\
   & = H_{#x#+1} + H_{#n#-#x#} - 2  \enspace .
\end{align*}
値$#x#\in(-1,n)\setminus\{0,\ldots,#n#-1\}$の場合も同様である（\figref{rbst-probs}(b)参照）。
\end{proof}

\begin{figure}
  \begin{center}
    \begin{tabular}{@{}c@{}}
      \includegraphics[width=\ScaleIfNeeded]{figs/rbst-probs-a} \\ (a) \\[2ex]
      \includegraphics[width=\ScaleIfNeeded]{figs/rbst-probs-b} \\ (b) \\[2ex]
    \end{tabular}
  \end{center}
  \caption{#x#の探索経路に各要素が現れる確率~(a)、#x#が整数のとき~(b)~#x#が整数でないとき}
  \figlabel{rbst-probs}
\end{figure}

\subsection{要約}

次の定理はランダム二分探索木の性能をまとめたものだ。

\begin{thm}\thmlabel{rbs}
ランダム二分探索木の構築にかかる時間は$O(#n#\log #n#)$である。
ランダム二分探索木における#find(x)#の実行時間の期待値は$O(\log #n#)$である。
\end{thm}

\thmref{rbs}における期待値は、ランダム二分探索木を作るための置換のランダム性に基づく。つまり、#x#をランダムに選ぶことには依存しておらず、任意の#x#について\thmref{rbs}は成り立つ。

% XXX: Randomized Binary Search Tree と random binary search tree をどう訳し分けるか -- YJ: ランダム化二分探索木？動的ランダム二分探索木？ 原著はこのsecではTreapをRandomized binary search treeの一つとして紹介しているのにかかわらずexerciseのところではMartinezによる変種こそをrandomized binary search treeと呼んで２つを対比している。
%\section{#Treap#: A Randomized Binary Search Tree}
\section{#Treap#: 動的ランダム二分探索木}
\seclabel{treap}

\index{Treap@#Treap#}%
前節で説明したランダム二分探索木の問題は動的でないことだ。
すなわち#SSet#インターフェースの#add(x)#・#remove(x)#をサポートしていないのである。
この節では#Treap#というデータ構造を説明する。
これは\lemref{rbs}を使って#SSet#インターフェースを実装するデータ構造である。
\footnote{#Treap#の名はこのデータ構造が二分木 \textbf{tr}ee(\secref{binarysearchtree})でありヒープ h\textbf{eap}(\chapref{heaps}) でもあることによる。}

#Treap#のノードは値#x#を持つ点で#BinarySearchTree#に似ているが、それに加えて一意な\emph{優先度}#p#を持つ。
この#p#はランダムに割り当てられる。
\javaimport{ods/Treap.Node<T>}
\cppimport{ods/Treap.TreapNode}
#Treap#のノードは、二分探索木の性質に加えて、\emph{ヒープ性 (heap property)}も満たす。
\begin{itemize}
\item （ヒープ性）根でない任意のノード#u#について$#u.parent.p# < #u.p#$が成り立つ。
      \ejindex{heap property}{ひーぷせい@ヒープ性}%
\end{itemize}
言い換えると、どのノードの優先度も、そのいずれの子ノードの優先度よりも小さい。
\figref{treap}に#Treap#の例を示した。

\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/treap}
  \end{center}
  \caption{整数$0,\ldots,9$を含む#Treap#の例。ノード#u#は$#u.x#,#u.p#$を含む四角形として描かれている。}
  \figlabel{treap}
\end{figure}

ヒープ性と二分探索木の性質とを共に満たすので、キー#x#と優先度#p#が決まれば#Treap#の形状は一意に定まる。
ヒープ性から、最小の優先度を持つノードが#Treap#の根#r#である。
二分探索木の性質から、#r.x#より小さなキーを持つノードは#r.left#を根とする部分木に含まれ、#r.x#より大さなキーを持つノードは#r.right#を根とする部分木に含まれる。

#Treap#の優先度の重要な特徴は、値#x#に対して一意であり、かつランダムであることだ。
このことから#Treap#の2つ等価な解釈の仕方がある。
先ほど定義したように、#Treap#はヒープ性と二分探索木性とを共に満たす。
別の角度から見ると、#Treap#は優先度の昇順にノードが追加される#BinarySearchTree#だと解釈してもよい。
例えば、空の#BinarySearchTree#に対して値$(#x#,#p#)$を次の順で追加すると、\figref{treap}の#Treap#を得られる。
\[
  \langle
   (3,1), (1,6), (0,9), (5,11), (4,14), (9,17), (7,22), (6,42), (8,49), (2,99)
  \rangle
\]

#Treap#におけるノードの優先度はランダムに決まるので、これはキーをランダムに置換するのと同じである。
例えば上の例は次の置換に対応する。
\[
  \langle 3, 1, 0, 5, 9, 4, 7, 6, 8, 2 \rangle
\]
この順番で要素を空の#BinarySearchTree#に追加すると、先ほどの#Treap#に対応する#BinarySearchTree#が得られる。
以上より#Treap#の形状はランダム二分探索木と同様に決まることがわかっただろう。
特に、キー#x#をそのランクに置き換えれば
\footnote{#x#を集合$S$の要素とするとき、#x#のランクとは$S$の要素のうち#x#より小さいものの個数である。}
\lemref{rbs}を#Treap#にも適用できる。
\lemref{rbs}を#Treap#のために言い換えると次のようになる。
\begin{lem}\lemlabel{rbs-treap}
  #n#個のキーからなる集合$S$を保持する#Treap#について次のことが成り立つ。
  \begin{enumerate}
    \item 任意の$#x#\in S$について#x#の探索経路の長さの期待値は$H_{r(#x#)+1} + H_{#n#-r(#x#)} - 2$である。
    \item 任意の$#x#\not\in S$について#x#の探索経路の長さの期待値は$H_{r(#x#)} + H_{#n#-r(#x#)}$である。
  \end{enumerate}
  ここで$r(#x#)$は集合$S\cup\{#x#\}$における#x#のランクである。
\end{lem}
繰り返しになるが、\lemref{rbs-treap}の期待値は優先度のランダム性に基づくもので、キーがランダムだとは仮定していない。

\lemref{rbs-treap}より、#Treap#の#find(x)#は効率良く実装できる。
しかし本当に有用なのは#add(x)#と#delete(x)#を実装できることだ。
このために木を回転する操作を使ってヒープ性を保つ。
\figref{rotations}を参照せよ。
二分探索木の\emph{回転 (rotation)}とは
\ejindex{rotation}{かいてん@回転}%
ノード#w#とその親#u#について、二分探索木の性質を保ちながら#w#と#u#の親子関係を逆転する操作である。
回転には\emph{右回転 (right rotation)}と\emph{左回転 (left rotation)}の二種類があり、#w#が#u#の右の子なら右回転を、左の#w#が#u#の左の子なら左回転を使う。
\ejindex{left rotation}{ひだりかいてん@左回転}%
\ejindex{right rotation}{みぎかいてん@右回転}%

\begin{figure}
  \begin{center}
     \includegraphics[width=\ScaleIfNeeded]{figs/rotation}
  \end{center}
  \caption{二分探索木の左回転・右回転}
  \figlabel{rotations}
\end{figure}

これを実装するためには、2つの場合を処理し、コーナーケース（#u#が根である場合）にも注意しなければならない。
そのためコードは\figref{rotations}から想像するものより少し長くなる。
\codeimport{ods/BinarySearchTree.rotateLeft(u).rotateRight(u)}
\label{page:rotations}
#Treap#における回転の重要な性質は、#w#の深さが1減り#u#の深さが1増えることだ。

回転を使って#add(x)#を次のように実装できる。
新しいノード#u#を作り、#u.x=x#とし、#u.p#を乱数で初期化する。
#u#を#BinarySearchTree#の#add(x)#アルゴリズムを使って追加する。
このとき#u#は#Treap#の葉になる。
ここで#Treap#は二分探索木性を満たすが、一方ヒープ性を満たすとは限らない。
具体的には#u.parent.p > u.p#だとこの#Treap#はヒープ性を犯している。
この場合、#w#=#u.parent#として回転を実行し、#u#を#w#の親にする。
このときまだ#u#がヒープ性を犯しているなら、もう一度回転を実行する。
この度に#u#の深さは1減り、#u#が根になるか$#u.parent.p# < #u.p#$を満たすと処理は終了する。
\codeimport{ods/Treap.add(x).bubbleUp(u)}
\figref{treap-add}に#add(x)#操作の例を示した。

\begin{figure}
  \begin{center}
  \includegraphics[width=\ScaleIfNeeded]{figs/treap-insert-a} \\
  \includegraphics[width=\ScaleIfNeeded]{figs/treap-insert-b} \\
  \includegraphics[width=\ScaleIfNeeded]{figs/treap-insert-c} \\
  \end{center}
  \caption{\figref{treap}の#Treap#に値1.5を追加する。}
  \figlabel{treap-add}
\end{figure}

#add(x)#操作の実行時間は#x#の探索経路の長さと、新たに追加されたノード#u#を#Treap#におけるあるべき位置まで移動するための回転する回数から求まる。
\lemref{rbs-treap}より探索経路の長さの期待値は$2\ln #n#+O(1)$以下である。
さらに回転のたびに#u#の深さは減る。
#u#が根になると処理が終了するので、回転回数の期待値は探索経路長の期待値以下である。
よって、#Treap#における#add(x)#の実行時間の期待値は$O(\log #n#)$である。
（\excref{treap-rotates}はこの操作における回転の回数の期待値は実は$O(1)$であることを示す問題である。）
%% XXX: \excref{treap-rotates} が問7.3となっているが、問7.5である。（excercise は 7.3 節であるが）-- 対応済み

#Treap#における#remove(x)#は#add(x)#の逆である。
#x#を含むノード#u#を探し、#u#が葉に来るまで下方向に回転を繰り返し、最後に#u#を取り外す。
#u#を下方向に動かすとき、右に回転するか左に回転するかの選択肢があることに注意する。
この選択は次の規則に従う。
\begin{enumerate}
\item #u.left#と#u.right#がいずれも#null#なら、#u#は葉なので回転の必要はない
\item #u.left#または#u.right#が#null#なら、#null#でない方と回転で#u#を入れ替える
\item $#u.left.p# < #u.right.p#$ならば右に回転し、そうでないなら左に回転する
\end{enumerate}
この規則により#Treap#は連結であり、またヒープ性も保たれることがわかる。
\codeimport{ods/Treap.remove(x).trickleDown(u)}
\figref{treap-remove}に#remove(x)#の例を示した。
\begin{figure}
  \begin{center}
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-a} \\
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-b} \\
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-c} \\
  \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/treap-delete-d}
  \end{center}
  \caption{\figref{treap}の#Treap#から値9を削除する。}
  \figlabel{treap-remove}
\end{figure}

#remove(x)#の実行時間の解析におけるポイントは、#add(x)#の逆の操作になっていることだ。
特に#x#を同じ優先度#u.p#で再挿入することを考えると、#add(x)#操作はちょうど同じ数の回転を実行し、#Treap#は#remove(x)#の直前の状態に戻る。
（\figref{treap-remove}を下から上に見ると値9を#Treap#に追加している様子になっている。）
これは大きさ#n#の#Treap#の#remove(x)#操作の実行時間の期待値は、大きさ#n-1#の#Treap#の#add(x)#操作の実行時間の期待値に比例するということである。
すなわち、#remove(x)#の実行時間の期待値は$O(\log #n#)$である。

\subsection{要約}

次の定理は#Treap#の性能をまとめるものだ。

\begin{thm}
#Treap#は#SSet#インターフェースを実装する。
#Treap#は#add(x)#・#remove(x)#・#find(x)#をサポートし、いずれの実行時間の期待値も$O(\log #n#)$である。
\end{thm}

#Treap#と#SkiplistSSet#を比べてみるのは面白いだろう。
いずれも#SSet#の実装で、各操作の実行時間の期待値は$O(\log #n#)$である。
どちらのデータ構造でも#add(x)#・#remove(x)#は検索に続く定数回のポインタの更新からなる。
（下の\excref{treap-rotates}を見よ）
%% XXX: \excref{treap-rotates} が問7.3となっているが、問7.5である。（excercise は 7.3 節であるが）-- 対応済み
よってどちらのデータ構造でも探索経路の長さの期待値が性能を決める重要な値である。
#SkiplistSSet#では探索経路の長さの期待値は次のようである。
\[
     2\log #n# + O(1)
\]
#Treap#では次のようである。
\[
    2\ln #n# +O(1) \approx 1.386\log #n#  + O(1)
\]
よって#Treap#における探索経路の方が短く、各操作も#Skiplist#よりも#Treap#の方がかなり速いと解釈できるだろう。
% XXX: ここも\excrefの参照先を修正する必要がある -- 対応済み
\chapref{skiplists}の\excref{skiplist-opt}で示したように、偏ったコイントスを使って、#Skiplist#における探索経路の長さの期待値を次のように減らせる。
%\bf{XXX: SkiplistSSetの誤植?} % 導入では実装+インターフェイスの名前であるSkiplistSSetを使い、実装の違いによる計算量の議論に移るところで実装の名前であるSkiplistにしていると思う。
\[
     e\ln #n# + O(1) \approx 1.884\log #n# + O(1)
\]
この最適化を採用しても、#SkiplistSSet#における探索経路の期待値は、やはり#Treap#のそれよりだいぶ長いのである。

\section{ディスカッションと練習問題}

ランダム二分探索木についての研究は多岐に渡る。
Devroye\cite{d88}が\lemref{rbs}とそれに関連する結果とを証明した。
いくつかのより強い事実も示されているが、その中でもっとも印象的なのはReed\cite{r03}の成果である。
この文献ではランダム二分探索木の高さの期待値は次の式で表せることを示した。
\[
  \alpha\ln n - \beta\ln\ln n + O(1)
\]
ここで$\alpha\approx4.31107$は$[2,\infty)$範囲での$\alpha\ln((2e/\alpha))=1$の解であり、$\beta=\frac{3}{2\ln(\alpha/2)}$である。
加えて、高さの分散は定数であることも示している。

#Treap#という名前はSeidelとAragon\cite{as96}が提案した。
この文献は#Treap#とその変種いくつかについて述べている。
しかし、基本的な#Treap#のアイデアはVuillemin\cite{v80}が先んじて研究しており、この文献ではこのデータ構造をCartesian treeと呼んでいた。

#Treap#のメモリ使用量を最適化する方法に、各ノードにおいて優先度#p#を明示的には保存せずに済ます技法がある。
その代わりに#u#のメモリアドレスのハッシュ値を#u#の優先度として用いる。
このやり方で実用的には上手く動作するハッシュ関数が多いが、\lemref{rbs}の証明の正しさを保つためには、\emph{min-wise independent性}を満たす関数族からランダムに選出した関数をハッシュ関数として使わなければならない。
\ejindex{min-wise independence}{min-wise independenceせい@min-wise independence性}%
min-wise independent性とは次の性質である。
相異なる任意の値$x_1,\ldots,x_k$について、それぞれのハッシュ値$h(x_1),\ldots,h(x_k)$は高い確率で相異なる値を取る。
すなわち、ある定数$c$が存在して、任意の$i\in\{1,\ldots,k\}$について次の式が成り立つ。
\[
   \Pr\{h(x_i) = \min\{h(x_1),\ldots,h(x_k)\}\} \le c/k
\]
この性質を持つハッシュ関数で、実装が簡単、かつ高速なものとして
\emph{tabulation hashing}がある。（\secref{tabulation}を参照せよ。）
\ejindex{tabulation hashing}{tabulation hashing}%
\ejindex{hashing!tabulation}{はっしゅほう@ハッシュ法!tabulation}%

#Treap#の他の変種であって、優先度を各ノードに蓄えないものとして、Mart\'\i nezとRoura \cite{mr98}による動的ランダム二分探索木がある。
\ejindex{randomized binary search tree}{どうてきらんだむにぶんたんさくぎ@動的ランダム二分探索木}%
\ejindex{binary search tree!randomized}{にぶんたんさくぎ@二分探索木!どうてきらんだむ@動的ランダム}%
任意のノード#u#は#u#を根とする部分木の大きさ#u.size#を保持する。
#add(x)#・#remove(x)#いずれのアルゴリズムも乱択化されている。
#x#を#u#を根とする部分木に追加するアルゴリズムは次のものである。
\begin{enumerate}
   \item 確率$1/(#size(u)#+1)$で#x#はふつうに葉として追加され、回転によって#x#は部分木の根に向けて動いてくる。
   \item そうでなければ（すなわち確率$1-1/(#size(u)#+1)$で、#x#は#u.left#または#u.right#の適切な方を根とする部分木に再帰的に追加される。
\end{enumerate}
1つめの場合は#Treap#における#add(x)#において#x#のノードがランダムな優先度として#size(u)#個のいずれの値よりも小さい値を取る場合に対応しており、この事象の発生確率をそのままアルゴリズムに使っている。

#x#を動的ランダム二分探索木から削除するやり方は#Treap#における削除と似ている。
#x#を含むノード#u#を見つけ、これが葉に到達するまで繰り返し深さを増やしながら回転し、そこで木から切り離す。
各ステップにおける回転が右か左かをランダムに決める。
\begin{enumerate}
  \item
  確率#u.left.size/(u.size-1)#で#u#において右回転を行う。
  すなわち#u.left#を部分木の根に持ってくる。
  \item
  確率#u.right.size/(u.size-1)#で#u#において左回転を行う。
  すなわち#u.right#を部分木の根に持ってくる。
\end{enumerate}
こちらの確率も#Treap#において#u#で左右の回転を行う確率に等しいことを簡単に確認できる。

#Treap#と比べてこの動的ランダム二分探索木には短所がある。
要素の追加・削除の際にランダムな選択を多く行うことと、部分木の大きさを保持しなければならないことだ。
この動的ランダム二分探索木の長所は、部分木の大きさを他の目的にも使えることだ。
例えばランクを$O(\log #n#)$の期待実行時間で計算する際にも流用できる。（\excref{treap-get}を参照せよ。）
一方、#Treap#の優先度には木のバランスを保つ以外の用途はない。

\begin{exc}
  \figref{treap}の#Treap#に4.5を優先度7で追加し、続いて値7.5を優先度20で追加する様子を図示せよ。
\end{exc}

\begin{exc}
  \figref{treap}の#Treap#から5と7を削除する様子を図示せよ。
\end{exc}

\begin{exc}
  \figref{rbs-lvc}の右の木を生成する操作の列が$21,964,800$通りあることを示せ。（ヒント：高さ$h$の完全二分木の個数に関する漸化式を作り、$h=3$の場合を評価せよ。）
\end{exc}

\begin{exc}
  #permute(a)#メソッドを設計・実装せよ。
  これは#n#個の相異なる値を含む配列#a#を入力とし、#a#のランダムな置換を返すものである。
  実行時間は$O(#n#)$であり、$#n#!$通りの置換がいずれも当確率で現れる必要がある。
\end{exc}

\begin{exc}\exclabel{treap-rotates}
\lemref{rbs-treap}を利用して、#add(x)#における回転回数の期待値が$O(1)$であることを示せ。（このことから#remove(x)#の場合も同様のことがわかる。）
\end{exc}

\begin{exc}
#Treap#の実装を明示的に優先度を保持しないように変更せよ。
その際優先度として、各ノードのハッシュ値を利用せよ。
\end{exc}

\begin{exc}
二分探索木の各ノード#u#は高さ#u.height#、#u#を根とする部分木の大きさ#u.size#を保持していると仮定する。
  \begin{enumerate}
    \item 左または右の回転を#u#で実行すると、回転によって影響を受けるすべてのノードにおける2つの値をそれぞれ定数時間で更新できることを示せ。
    \item 各ノードの深さも保持することにすると、上と同様の結果が成り立たなくなることを説明せよ。
  \end{enumerate}
\end{exc}

\begin{exc}
  #n#要素からなる整列済み配列#a#から#Treap#を構築するアルゴリズムを設計・実装せよ。
  この操作の実行時間は最悪の場合でも$O(#n#)$である必要がある。
  また#a#の要素を順に#add(x)#メソッドで追加して得られる#Treap#と同一の#Treap#が得られなければならない。
\end{exc}

\begin{exc}
  \ejindex{finger}{ゆび@指}%
  \ejindex{finger search!in a treap}{ゆびたんさく@指探索!treap}%
  この問題では#Treap#において、与えられたポインタの近くにあるノードを効率的に見つける方法を明らかにする。
  \begin{enumerate}
    \item 各ノードが自身を根とする部分木における最大値・最小値を保持する#Treap#を設計・実装せよ。
    \item この情報を使って、#fingerFind(x,u)#を実装せよ。
	これは#u#の助けを借りて#find(x)#を実行する操作である。
	（#u#は#x#から遠くないノードであれば望ましい。）
	この操作は#u#から上に向かって進み$#w.min#\le #x#\le #w.max#$を満たすノード#w#を見つける。
	その後は#w#からふつうのやり方で#x#を検索する。
	（#fingerFind(x,u)#の実行時間は$O(1+\log r)$であることを示せる。
	ここで、$r$は#Treap#の要素であって、その値が#x#と#u.x#の間にあるものの数である。）
	\item #Treap#の実装を拡張し、#find(x)#の探索を開始するノードを、直近の#find(x)#で見つかったノードとするようにせよ。
  \end{enumerate}
\end{exc}

\begin{exc}\exclabel{treap-get}
#Treap#におけるランクが#i#であるキーを返す操作#get(i)#を設計・実装せよ。
（ヒント：各ノード#u#が#u#を根とする部分木の大きさを保持するようにするとよい。）
\end{exc}

\begin{exc}
  \index{TreapList@#TreapList#}
  #TreapList#を実装せよ。
  これは#List#インターフェースをTreapとして実装したものだ。
  各ノードはリストのアイテムを保持し、行きがけ順で辿るとリストに入っている順でアイテムが見つかる。
  #List#の操作#get(i)#・#set(i,x)#・#add(i,x)#・#remove(i)#の期待実行時間はいずれも$O(\log #n#)$である必要がある。
\end{exc}



\begin{exc}\exclabel{treap-split}
  #split(x)#をサポートする#Treap#を設計・実装せよ。
  この操作は#Treap#に含まれる#x#より大きいすべての値を削除し、削除された値をすべて含む新たな#Treap#を返すものである。

  \noindent 例：
  #t2 = t.split(x)#は#t#から#x#より大きい値をすべて削除し、削除した値をすべて含む新たな#Treap# #t2#を返す。
  #split(x)#の実行時間の期待値は$O(\log #n#)$である必要がある。

  \noindent 注意：
  この修正後も#size()#は定数時間で正しく動く必要がある。
  これは\excref{treap-get}のために必要である。
\end{exc}

\begin{exc}\exclabel{treap-join}
#split(x)#の逆の操作と見なせる#absorb(t2)#をサポートする#Treap#を設計・実装せよ。
この操作は#Treap# #t2#からすべての値を削除し、それらをレシーバーに追加する。
また、この操作は#t#の最小値はレシーバーの最大値よりも大きいことを前提とする。
なお、#absorb(t2)#の期待実行時間は$O(\log #n#)$である必要がある。
\end{exc}

\begin{exc}
  この節で説明したMartinezのrandomized binary search treesを実装せよ。
  また、#Treap#の実装と性能を比較せよ。
\end{exc}

