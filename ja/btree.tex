\chapter{外部メモリの探索}
\chaplabel{btree}
この本を通じて計算のモデルとしては\secref{model}で定義した#w#ビットのワードRAMモデルを使ってきた。
これは、コンピュータのランダムアクセスメモリはデータ構造内のすべてのデータを格納できるくらい大きいと暗に仮定していたということである。
しかし時にはこの仮定が成り立たないこともある。
大きすぎてどんなコンピュータのメモリにも収まりきらないデータはたくさん存在するのである。
このような場合、ハードディスクドライブ（HDD）・ソリッドステートドライブ（SSD）・ネットワーク越しのサーバーなどの外部ストレージにデータを蓄えざるを得ない。

\ejindex{external storage}{がいぶすとれーじ@外部ストレージ}%
\ejindex{external memory}{がいぶめもり@外部メモリ}%
\ejindex{hard disk}{はーどでぃすく@ハードディスク}%
\index{solid-state drive}%
外部ストレージへのデータアクセスは非常に遅い。
この本を書くのに使っているコンピュータでは、ハードディスクへの平均アクセス時間は19ms、SSDの場合は0.3msである。
これに対してにランダムアクセスメモリの場合は0.000113ms未満である。
RAMへのアクセスはSSDと比べて2500倍、HDDと比べて160000倍以上高速である。

%  HDD: Fantom ST3000DM001-9YN166 USB 3 external drive (3TB)
%  SSD: ATA OCZ-AGILITY 3 (60GB)
%  Mem: Mushkin Enhanced Essentials 4GB (2 x 2GB) 204-Pin DDR3 
%       SO-DIMM DDR3 1066 (PC3 8500) Dual Channel Kit Laptop Memory
%       Model 996643
%  RAM speed was estimated using this program:
% #include<stdlib.h>
% #include<stdio.h>
% #include<time.h>
% 
% int main(void) {
%    unsigned *a, x, i, n = 50000000;
%    clock_t start, stop;
% 
%    start = clock();
%    a = malloc(sizeof(unsigned)*n);
%    for(i = 0; i < n; i++) {
%      x |= a[rand()%n];
%    }
%    stop = clock();
%    printf("x=%x, %g\n", x, (((double)(stop-start))/(double)CLOCKS_PER_SEC)/(double)n);
%    free(a);
%    return 0;
% }

これらの速度は典型的な値である。
RAMへのランダムアクセスはHDDやSSDへのランダムアクセスと比べて数千倍高速である。
しかしアクセスにかかる時間だけを考えれば十分というわけではない。
HDDやSSDのバイトにアクセスするときには、実際は
\emph{ブロック}単位での読み出しが行われる。
\ejindex{block}{ぶろっく@ブロック}%
コンピュータに接続されるドライブは大きさ4096のブロックを持つ
\footnote{訳注：異なる大きさが使われることもあるが、ここでは簡単のため4096で統一している。}。
1バイトの読み出しをする度にドライブは4096バイトを返してくる。
このことを踏まえてデータ構造を設計すれば、この4096バイトを操作にうまく利用することができるだろう。

% morin@peewee:~/git/ods/latex$ sudo blockdev --report
% RO    RA   SSZ   BSZ   StartSec            Size   Device
% rw   256   512  4096          0     60022480896   /dev/sda   SSD
% rw   256  4096  4096        504   3000581885952   /dev/sdb1  HDD

これが\emph{外部メモリモデル}の背後にあるアイデアである。
\ejindex{external memory model}{がいぶめもりもでる@外部メモリモデル}%
\figref{em}にはこれを図示した。
このモデルではコンピュータはすべてのデータが保存されている大きな外部メモリにアクセスできる。
このメモリは\emph{ブロック}に分割されており、
\ejindex{block}{ぶろっく@ブロック}%
それぞれのブロックは$B$ワードからなる。
このコンピュータは有限の内部メモリも利用でき、ここで計算を実行できる。
内部メモリと外部メモリの間でブロックを転送するのには一定の時間がかかる。
内部メモリでの計算は\emph{タダ}である。つまり一切の時間がかからない。
この仮定は奇妙に感じるかもしれないが、外部メモリへのアクセスが非常に遅いことを強調した結果である。

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/em}}
  \caption{外部メモリモデルでは、外部メモリに含まれる要素#x#にアクセスするためには#x#を含むブロックをまるごとRAMに読み込む必要がある。}
  \figlabel{em}
\end{figure}

本格的な外部メモリモデルでは内部メモリの大きさもパラメータである。
しかし、この章で扱うデータ構造では内部メモリのサイズは$O(B+\log_B #n#)$で十分である。
これは定数個だけのブロックと、高さ$O(\log_B #n#)$だけのスタックに必要なメモリである。
多くの場合$O(B)$が支配的な項である。
例えば比較的小さい値$B=32$であっても、すべての$#n#\le 2^{160}$について$B\ge \log_B #n#$が成り立つ。
十進法では、$B\ge \log_B #n#$が以下の範囲で成り立つ。
\[
#n# \le 1\,461\,501\,637\,330\,902\,918\,203\,684\,832\,716\,283\,019\,655\,932\,542\,976
\]
% TODO caprice システムコールの脚注
\section{BlockStore}
\index{block store}%
\index{BlockStore@#BlockStore#}%
外部メモリにはHDDやSSDなど様々なデバイスが含まれる。
ブロックの大きさはデバイスごとに定義されており、それぞれ独自のシステムコールによってアクセスされる。
説明を単純にし、一般的なアイデアに焦点をあてるため、外部メモリのデバイスを#BlockStore#と呼ばれるオブジェクトに隠蔽する。
#BlockStore#はブロックの集まりを格納する。
% caprice 原文は memory block となっているが、他の訳文同様に、単純にブロックと呼んだほうが読みやすいと判断した
各ブロックの大きさは$B$である。
各ブロックは整数のインデックスによって一意に特定される。 % YJ インデックスに対応する日本語はあるか？
#BlockStore#は次の操作をサポートする。

\begin{enumerate}
  \item #readBlock(i)#：インデックス#i#のブロックの内容を返す。
  \item #writeBlock(i,b)#：インデックス#i#のブロックに#b#の内容を書く。
  \item #placeBlock(b)#：新たなインデックスを返し、そこに#b#の内容を書く。
  \item #freeBlock(i)#：インデックス#i#のブロックを開放する。これは指定したブロックの内容をもう使わず、このブロックに割り当てられていた外部メモリは別の用途に使ってよいことを示す。
\end{enumerate}

#BlockStore#は$B$バイトのブロックに分割されたディスク上のファイルだと考えるのが最も想像しやすいだろう。
このとき、#readBlock(i)#・#writeBlock(i,b)#は、このファイルのバイト列$#i#B,\ldots,(#i#+1)B-1$の読み・書きである。
さらに、#BlockStore#は利用可能なブロックからなる\emph{フリーリスト}を保持してもよい。 % YJ: Free listに対応するテクニカルタームが存在する？
#freeBlock(i)#により解放されたブロックはフリーリストに追加される。
こうすれば、#placeBlock(b)#はフリーリストのブロックを使い、利用可能なブロックがないときだけファイルの末尾に新しいブロックを追加するようにできる。

\section{B木}
\seclabel{btree}

この節では二分木の一般化である、$B$木と呼ばれる、外部メモリモデルにおいて効率的なデータ構造を紹介する。
それ以外にも$B$木は\secref{twofour}で説明した2-4木の自然な一般化だと考えることもできる。
（$B$木において$B=2$とおくと2-4木になる。）

\ejindex{B-tree@$B$-tree}{Bぎ@B木}%
任意の整数$B\ge 2$について\emph{$B$木}とは木であって、すべての葉は同じ深さにあり、すべての根でない内部ノードの子の数が$B$以上$2B$以下なものである。
ノード#u#の子は配列#u.children#に格納される。
ただし、子の数の条件は根では緩和され、2以上$2B$以下である。

% TALK upper bound は ルートが2Bの子を持つとき、つまり (2B)^(h) ではないのか？
% YJ: そうだと思う。根を含むすべての内部ノードが2B個の子を持つと(2B)^(h)になる。
$B$木の高さが$h$のとき、葉の数$\ell$は次の式を満たす。
%\footnote{訳注：左辺は根の子が２個のみで全ての内部ノードがB個の子を持つとき、右辺は葉以外のノードの子が全て2B個であるときの葉の数である。}。
\[
    2B^{h-1} \le \ell \le (2B)^{h}
\]
この式の左辺は根の子が$2$個のみで全ての内部ノードが$B$個の子を持つときの葉の数に対応し、右辺は葉以外のノードの子が全て$2B$個であるときの葉の数に対応する。
最初の不等式の両辺から対数を取り、項を並べ替えると次の式が得られる。
\begin{align*}
    h & \le \frac{\log \ell-1}{\log B} + 1  \\
      & \le \frac{\log \ell}{\log B} + 1 \\
      & = \log_B \ell + 1
\end{align*}
つまり、$B$木の高さは$B$を底とする葉の数の対数に比例する。

$B$木における各ノード#u#にはキーの配列$#u.keys#[0],\ldots,#u.keys#[2B-1]$を格納する。
#u#が$k$個の子を持つ内部ノードのとき、#u#に格納されるキーの数はちょうど$k-1$であり、それぞれ$#u.keys#[0],\ldots,#u.keys#[k-2]$に格納される。
#u.keys#における残りの$2B-k+1$個の配列のエントリは#null#にしておく。
#u#が根でない葉ノードのとき、#u#は$B-1$個以上$2B-1$個以下のキーを持つ。
$B$木のキーは二分探索木と同様の順序を守る。
$k-1$個のキーを格納する任意のノード#u#は次の式を満たす
%\footnote{訳注：文献によってはキー値の重複を許す場合もあるようだが、\secref{btree-amortized}で後述されるように、この本においては、B木の実装である#BTree#クラス（後述）は#SSet#インターフェースの実装だと説明されている。すなわち、要素の重複はない。}
\footnote{訳注：この本ではB木はキーの重複がない#SSet#インターフェースを実装するために使うため、等号なし不等号による。キーの重複があるmultisetの実装時は$#u.keys[0]# \leq #u.keys[1]# \leq \cdots \leq #u.keys#[k-2]$、$#u.children[i]# \preceq #u.keys[i]# \preceq #u.children[i+1]#$を満たす。}
。
\[
   #u.keys[0]# < #u.keys[1]# < \cdots < #u.keys#[k-2]
\]
% TALK これ、 < でいいのか？ [Cormen 09]だと<=で定義してるのだが % YJ: ここではSetの実装として定義しているためかと。Introduction to Algorithmでも<=で定義されていた。
#u#が内部ノードなら、任意の$#i#\in\{0,\ldots,k-2\}$について$#u.keys[i]#$は#u.children[i]#を根とする部分木に格納されるどのキーよりも大きく、$#u.children[i+1]#$を根とする部分木に格納されるどのキーよりも小さい。
つまり、厳密な書き方ではないが、次が成り立つ。
\[
   #u.children[i]# \prec #u.keys[i]# \prec #u.children[i+1]#
\]
$B=2$である$B$の例を\figref{btree}に示す。

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/btree-1}}
  \caption{$B=2$である$B$木}
  \figlabel{btree}
\end{figure}

$B$木のノードに格納されるデータの大きさは$O(B)$である。
そのため外部メモリのことを考えると、$B$木の$B$の値は外部メモリのブロックの大きさに合わせて選ばれる。
こうすれば外部メモリモデルにおいて$B$木の操作にかかる時間は、操作の際にアクセス（読み書き）するノードの数に比例する。

例えば、キーが4バイト整数であり、ノードのインデックスも4バイトであるとする。
このとき$B=256$とすれば各ノードは
\[
(4+4)\times 2B
 = 8\times512=4096
\]
バイトのデータを格納することになる。
この章の最初に説明したように、ハードディスクやSSDのブロックサイズは$4096$バイトなので、この$B$はこれらのデバイスに適した値である。

% caprice インデックスを添え字と訳すこともできるが、riやuiのようにiが変数名の末尾に使われているので、単にカタカナにしたほうがその点が読みやすいと判断した
#BTree#クラスは$B$木の実装である。
#BTree#のノードを格納する#BlockStore#オブジェクト#bs#と、根のインデックス#ri#を格納する。
また、他のデータ構造と同様に、整数#n#はデータ構造の要素数を表す。
\cppimport{ods/BTree.n.ri.bs}
\javaimport{ods/BTree.n.ri.bs}
\pcodeimport{ods/BTree.initialize(b)}

\subsection{要素の検索}

\figref{btree-find}に示した#find(x)#の実装は、二分探索木における#find(x)#の実装の一般化である。
#x#を検索するために、根から処理を開始し、ノード#u#のキーを利用して次に#u#の子のうちのどれに進むべきかを決める。

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/btree-2}}
  \caption{$B$木における成功する探索（4を探す）と、失敗する探索（16.5を探す）の様子。色を付けたノードは探索の途中に値を更新されるものである。}
  \figlabel{btree-find}
\end{figure}
より具体的には、ノード#u#にいるとき、まずは#x#が#u.keys#に格納されているかどうかを確認する。
格納されていれば、#x#が見つかったので処理を終了する。
そうでなければ、最小の$#u.keys[i]# > #x#$を満たす最小の整数#i#を求め、#u.children[i]#を根とする部分木に進んで探索を続ける。
もし#u.keys#に#x#より大きなキーがないときは、#u#の一番右の子に進んで探索を続ける。
二分探索木と同じように、このアルゴリズムは#x#より大きなキーのうち、最後に訪れたもの#z#を記録しておく。
#x#が見つからなかったときは、#x#以上の最小の値である#z#を返す。
\codeimport{ods/BTree.find(x)}
#find(x)#の肝は#findIt(a,x)#であり、これは#null#埋めされた配列#a#から#x#を探すメソッドである。
\figref{findit}に示したように、$#a#[0],\ldots,#a#[k-1]$にはキーが整列された状態で、$#a#[k],\ldots,#a#[#a.length#-1]$にはすべて#null#が入っている。
#x#がこの配列の#i#番目の位置に入っているとき、#findIt(a,x)#は$-#i#-1$を返す。 % TODO: YJ 場合分けのために負の値にするというのは低レベルの実装の都合に寄りすぎた説明で好きではない
そうでないときは、$#a[i]#>#x#$または$#a[i]#=#null#$を満たす最小のインデックス#i#を返す。
\begin{figure}
  \centering{\includegraphics[scale=0.90909]{figs/findit}}
  \caption{#findIt(a,27)#を実行する様子}
  \figlabel{findit}
\end{figure}
\codeimport{ods/BTree.findIt(a,x)}
#findIt(a,x)#は二分探索を使う。
\ejindex{binary search}{にぶんたんさく@二分探索}%
これは各ステップで探索空間を半分に減らすことで、$O(\log(#a.length#))$の時間で処理を終える。
ここでは$#a.length#=2B$なので#findIt(a,x)#の(RAMモデルでの)実行時間は$O(\log B)$である。

$B$木における#find(x)#の実行時間をいつものワードRAMモデル（全命令を数える）でも、または外部メモリモデル（アクセスするノードの数だけを数える）でも解析できる。
$B$木の葉は少なくともひとつのキーを格納し、$\ell$個の葉を持つ$B$木の高さは$O(\log_B\ell)$なので、#n#個のキーを格納する$B$木の高さは$O(\log_B #n#)$である。
よって、外部メモリモデルでは、#find(x)#の実行時間は$O(\log_B #n#)$である。
ワードRAMモデルにおける実行時間を計算するためには、アクセスするすべてのノードについて#findIt(a,x)#呼び出しのコストを考えればよい。
よって、この場合の#find(x)#の実行時間は次のようになる。
\[
   O(\log_B #n#)\times O(\log B) = O(\log #n#)
\]

\subsection{要素の追加}
\seclabel{btree-elem-add}

$B$木と\secref{binarysearchtree}で説明した#BinarySearchTree#との重要な違いは、$B$木のノードは親へのポインタを持っていないことである。
この理由を軽く説明する。
親へのポインタがないため、$B$木における#add(x)#・#remove(x)#は再帰を使うのがもっとも簡単な実装方法となる。

他のバランスされた探索木と同様に、#add(x)#の際に何らかのバランス調整が必要になる。
$B$木ではこれはノードの\emph{分割}によって行われる。
\ejindex{split}{ぶんかつ@分割}%
\figref{btree-split}を見ながら続く説明を読んで欲しい（訳注： \cent\ 記号は後の節で実行時間の解析に使うため、ここでは無視してよい。）。 % 訳注はやや冗長か？
分割はふたつの再帰レベルに渡って起きるが、$2B$個のキーを含み$2B+1$個の子を持つノード#u#を引数とする操作であると考えると理解しやすいだろう。
新たなノード#w#を作り、このノードは$#u.children#[B],\ldots,#u.children#[2B]$を引き受ける。
#u#のキーのうち大きい方から$B$個$#u.keys#[B],\ldots,#u.keys#[2B-1]$も#w#に持たせる。
この段階で、#u#は$B$個の子と、$B$個のキーを持っている。
さらに追加で$#u.keys#[B-1]$は#u#の親に渡され、#u#の親は#w#も子として引き受ける。

分割操作は3つのノードを修正する。
これは#u#・#u#の親・新たなノード#w#である。
これが$B$木において親へのポインタを持たない理由なのである。
もし親へのポインタがあると、#w#が引き取る$B+1$個の子すべてについて、親へのポインタを#w#へのポインタとして書き換える必要がある。
これは外部メモリのアクセスを3回から$B+4$回に増やすことになり、$B$が大きいときに$B$木が非効率になってしまう。

\begin{figure}
   \centering{\begin{tabular}{@{}l@{}}
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-split-1} \\[2ex]
     \multicolumn{1}{c}{#u.split()#} \\ 
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-split-2} \\
   \end{tabular}}
   \caption{$B=3$である$B$木における、ノード#u#の分割。キー$#u.keys#[2]=\mathrm{m}$は#u#からその親に移る。}
   \figlabel{btree-split}
\end{figure}

$B$木における#add(x)#の様子を\figref{btree-add}に示す。
概要としては、まずこのメソッドは値#x#を追加する葉#u#を見つける。
このときに#u#が一杯になった場合には（つまり既に$2B-1$個のキーを持っていれば）、#u#を分割する。この結果#u#の親が一杯になった場合には、#u#の親を分割する。さらにその結果#u#の親の親が一杯になった場合には...ということを繰り返す。
ひとつずつ木を上に登りながら、一杯でないノードを見つけるか、根を分割するまでこの処理を繰り返す。
一杯でないノードが見つかった場合には単に処理を終了する。
根を分割した場合には、新たな根を作り、元の根を分割して得られたふたつのノードを共に新たな根の子にする
\footnote{訳注：似た議論を\secref{redblack-add-by-divide}で行なったことを思い出そう。}。

\begin{figure}
   \centering{\begin{tabular}{@{}l@{}}
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-add-1} \\[2ex]
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-add-2} \\[2ex]
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-add-3}
   \end{tabular}}
   \caption{#BTree#における#add(x)#の様子。値21を追加すると、ふたつのノードが分割される。}
   \figlabel{btree-add}
\end{figure}

#add(x)#の実行について整理すると、まずは根からスタートし、#x#を追加すべき葉を見つけ、その葉に#x#を追加し、根に向かって戻りながら、その途中で見かけた一杯になったノードを分割する。
このような概要を頭に入れて、次はこのメソッドをどう再帰的に実装するかの詳細を見ていく。

#add(x)#が行う処理のほとんどは#addRecursive(x,ui)#が担当する。
これは識別子#ui#を持つノード#u#を根とする部分木に#x#を追加するメソッドだ。
#u#が葉なら、単に#x#を#u.keys#に挿入する。
そうでないときは、#x#を#u#の子のうち適切なもの$#u#'$に再帰的に追加する。
この再帰的な呼び出しはふつうは#null#を返すが、$#u#'$が分割されるときは新たに作られたノード#w#の参照を返す。
この場合、#u#は#w#を子にした上で、その#w#の最初のキーを奪って、$#u#'$の分割処理を終える。

#x#が（#u#または#u#の子孫に）追加された後、#addRecursive(x,ui)#は#u#の持つキーが多すぎないか（$2B-1$より多くないか）どうかを確認する。
もしそうなら#u#を\emph{分割}しなければならず、#u.split()#を呼ぶ。
#u.split()#の返り値である新しいノードは#addRecursive(x,ui)#の返り値として使われる。
\codeimport{ods/BTree.addRecursive(x,ui)}

#addRecursive(x,ui)#は#add(x)#のヘルパーであり、#add(x)#は#addRecursive(x,ri)#を呼んで#x#を$B$木の根に挿入する
\footnote{訳注：整数#ri#はBTreeクラスで根のインデックスとして定義したことを思い出そう。一方で#addRecursive(x,ui)#の引数として用いられている#ui#は、最初の呼び出しでは#ri#そのものであるが、以降はノード#u#のインデックスであることに注意。}。
#addRecursive(x,ri)#によって根が分割されるときは、古い根と古い根の分割において新たに作られたノードとを、新たな根は子として持つ。
\codeimport{ods/BTree.add(x)}

#add(x)#とそのヘルパー#addRecursive(x,ui)#は二段階に分けて分析できる。

\begin{description}
  \item[下向きに進む段階]
  再帰の下向きに進む段階では、#x#を追加する前に、各ノードにて#findIt(a,x)#を呼び、#BTree#のノードを順番にアクセスする。
#find(x)#と同様に、このメソッドの実行時間は、外部メモリモデルでは$O(\log_B #n#)$、ワードRAMモデルでは$O(\log #n#)$である。

  \item[上向きに進む段階]
  再帰の上向きに進む段階では、#x#を追加した後、合わせて最大$O(\log_B #n#)$回の分割を行う。
  各分割は3つのノードだけに影響するので、この段階の実行時間は外部メモリモデルでは$O(\log_B #n#)$である。
  しかし、各分割は$B$個のキーと子をノードからノードに移すので、ワードRAMモデルでは、この実行時間は$O(B\log #n#)$である。
  \end{description}

$B$の値はかなり大きく、$\log #n#$よりもだいぶ大きいことを思い出そう。
そのため、ワードRAMモデルでは$B$木への要素の追加はバランスされた二分探索木よりもかなり遅いかもしれない。
\secref{btree-amortized}では、それほど悪くはないことを示す。
実は償却すると、#add(x)#で実行される分割の回数は定数なのである。
そのため、ワードRAMモデルにおける#add(x)#の償却実行時間は$O(B+\log #n#)$なのである。

\subsection{ノードの削除}
#BTree#における#remove(x)#も再帰で実装するのが簡単だ。
#remove(x)#を再帰で実装するといくつかのメソッドは複雑になるものの、\figref{btree-remove-full}に示したように全体としては非常に素直になる。
ここでは結局、うまくキーを入れ替えて、ある葉#u#から値$#x#'$を削除したい。
$#x#'$を削除すると、#u#の持つキーの数は$B-1$未満になるかもしれない。
この状態を\emph{アンダーフロー}と呼ぶことにする。
\ejindex{underflow}{あんだーふろー@アンダーフロー}%

\begin{figure}
   \centering{\begin{tabular}{@{}l@{}}
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-full-1} \\[2ex]
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-full-2} \\[2ex]
     \multicolumn{1}{c}{#merge(v,w)#} \\
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-full-3} \\[2ex]
     \multicolumn{1}{c}{#shiftLR(w,v)#} \\
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-full-4} \\[2ex]
   \end{tabular}}
   \caption{この$B$木から値4を削除すると、併合・借用が一回ずつ発生する。}
   \figlabel{btree-remove-full}
\end{figure}

アンダーフローが発生すると、#u#は兄弟からキーを借りてくるか、兄弟のいずれかと併合される。
#u#が兄弟と併合される場合には、#u#の親が持つ子とキーの数はそれぞれ1減り、その結果今度は#u#の親でアンダーフローが発生するかもしれない。
これは再度、兄弟からキーを借りるか、兄弟と併合されるかで解決されるが、併合する場合には、今度は#u#の親の親がアンダーフローするかもしれない。
この処理は、根に向かいながら行われ、アンダーフローが発生しなくなるか、根のふたつの子が一つに併合されるかすると終了する。
後者の場合には、根は削除され、その唯一の子が新たな根になる。

続いて、各ステップの実装方法を詳細に見ていく。
#remove(x)#はまず、削除したい要素#x#を見つける。
#x#が葉で見つかれば、#x#をこの葉から削除する。
そうでなく、#x#がある内部ノード#u#の#u.keys[i]#で見つかれば、#u.children[i+1]#を根とする部分木の最小値#x'#を削除する。
#x'#は#x#より大きい値を格納する#BTree#の最小値である。
続いて、#x'#の値で#u.keys[i]#の#x#を置き換える。
\figref{btree-remove}にこの処理の様子を示す。

\begin{figure}
   \centering{\begin{tabular}{@{}l@{}}
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-1} \\[2ex]
     \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
     \includegraphics[width=\ScaleIfNeeded]{figs/btree-remove-2}
   \end{tabular}}
   \caption{#BTree#において#remove(x)#を実行する様子。値$#x#=10$を削除するとき、その値を$#x'#=11$で上書きし、値11を含む葉を削除する。}
   \figlabel{btree-remove}
\end{figure}

#removeRecursive(x,ui)#は上のアルゴリズムの再帰的な実装である。
\codeimport{ods/BTree.removeRecursive(x,ui).removeSmallest(ui)}

#u#の#i#番目の子から値#x#を再帰的に削除したあと、#removeRecursive(x,ui)#はこの子が少なくとも$B-1$個のキーを持っていることを保証しなければならない。
先のコードでは#checkUnderflow(x,i)#がこの処理を行っている。
これは#u#の#i#番目の子についてアンダーフローの発生を確認し、修正する。
#w#を#u#の#i#番目の子とする。
#w#が$B-2$個のキーしか持たないなら、修正の必要がある。
これには#w#の兄弟を利用する。
#u#の$#i#+1$番目または$#i#-1$番目の子を使う。
ふつうは#u#の$#i#-1$番目の子#v#、つまり#w#のすぐ左の兄弟を使う。
$#i#=0$のときだけはこれがうまくいかないので、#w#のすぐ右の兄弟を使う。
\codeimport{ods/BTree.checkUnderflow(u,i)}
ここでは$#i#\neq 0$の場合のみを考え、#u#の#i#番目の子で発生したアンダーフローは #u#の$(#i#-1)$番目の子の助けを借りて修正できることを確認する。
$#i#=0$の場合も同様に処理できるので、詳細は付属のソースコードを参照してほしい。

#w#におけるアンダーフローを解決するために、#w#のためのキー（や子）を見つけてくる必要がある。
これを行うための操作はふたつある。

\begin{description}
  \item[借用]
  \ejindex{borrow}{しゃくよう@借用}%
  #w#の兄弟#v#が$B-1$個よりも多くのキーを持っているなら、#w#はキーを（あとは可能なら子も）#v#から借りる。
  より具体的には#v#が#size(v)#個のキーを持つなら、#v#と#w#とが持っているキーの個数の合計は次のようになる。
  \[
     B-2 + #size(w)# \ge 2B-2
  \]
  よって#v#から#w#にキーを移し、#v#と#w#のいずれもが$B-1$個以上のキーを持つ状態にできる。
  この操作の様子を\figref{btree-borrow}に示す。

  \begin{figure}
      \centering{\begin{tabular}{@{}l@{}}
       \includegraphics[width=\ScaleIfNeeded]{figs/btree-borrow-1} \\[2ex]
       \multicolumn{1}{c}{#shiftRL(v,w)#} \\ 
       \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
       \includegraphics[width=\ScaleIfNeeded]{figs/btree-borrow-2} \\
     \end{tabular}}
    \caption{#v#が$B-1$個より多くのキーを持つ時、#w#は#v#からキーを借りることができる。}
    \figlabel{btree-borrow}
  \end{figure}

  \item[併合]
  \ejindex{merge}{へいごう@併合}%
  #v#が$B-1$個だけしかキーを持っていないとき、#v#にはキーを渡す余裕が無いので、もっと思い切ったことをする必要がある。
  そのために、\figref{btree-merge}に示したように#v#と#w#とを\emph{併合}する。
  併合は分割の逆の操作である。
  これは合わせて$2B-3$個のキーを持つふたつのノードを併合し、$2B-2$個のキーを持つひとつのノードとする操作である。
  （併合されたノードのキー数がひとつ増えているのは、#v#と#w#を併合すると、それらの共通の親#u#の子の数がひとつ減ることから、#u#は保有するキーのひとつを、併合されたノードに受け渡す必要があるためだ。）

  \begin{figure}
     \centering{\begin{tabular}{@{}l@{}}
       \includegraphics[width=\ScaleIfNeeded]{figs/btree-merge-1} \\[2ex]
       \multicolumn{1}{c}{#merge(v,w)#} \\ 
       \multicolumn{1}{c}{$\Downarrow$} \\[2ex]
       \includegraphics[width=\ScaleIfNeeded]{figs/btree-merge-2} \\
     \end{tabular}}
     \caption{$B=3$である$B$木の兄弟#v#・#w#を併合する。}
     \figlabel{btree-merge}
  \end{figure}
\end{description}

\codeimport{ods/BTree.checkUnderflowNonZero(u,i).checkUnderflowZero(u,i)}

まとめると、$B$木における#remove(x)#は根から葉まである経路を辿り、#x'#を葉#u#から削除し、その後0回以上の併合を#u#とその祖先に対して実行し、高々一回借用操作を行う。
併合や借用には3つのノードしか修正せず、$O(\log_B #n#)$回だけの操作を行うので、外部メモリモデルにおける全体としての実行時間は$O(\log_B #n#)$である。
しかしここでも、ワードRAMモデルでは併合やノードを借りる操作には$O(B)$だけの時間がかかるので、ワードRAMモデルにおける#remove(x)#の実行時間は$O(B\log_B #n#)$であるとしか（現時点では）言えない。

\subsection{$B$木の償却解析}
\seclabel{btree-amortized}

ここまでに、次のことを示してきた。
\begin{enumerate}
  \item 外部メモリモデルでは、$B$木における#find(x)#・#add(x)#・#remove(x)#の実行時間はそれぞれ$O(\log_B #n#)$である。
  \item ワードRAMモデルでは、#find(x)#の実行時間は$O(\log #n#)$であり、#add(x)#・#remove(x)#の実行時間は$O(B\log #n#)$である。
\end{enumerate}

次の補題は、これまで$B$木における分割・併合操作の数を過大評価していたことを示す。

\begin{lem}\lemlabel{btree-split}
空の$B$木からはじめて、#add(x)#・#remove(x)#からなる$m$個の操作の列を順に実行するとき、分割・併合・借用は合わせて高々$3m/2$回しか実行されない。
\end{lem}

\begin{proof}
   $B=2$の特別な場合について、\secref{redblack-summary}で既に証明の概要を示している。
   % Scapegoat木はクレジット -> 預金と訳している。とりあえず一貫性を保つため預金にした。
   この補題はここでは出納法で証明する。
   \ejindex{credit scheme}{すいとうほう@出納法}%
  \begin{enumerate}
    \item 分割・併合・借用の際に2の預金を支払う（失う）。
    \item #add(x)#または#remove(x)#の際には、最大3の預金が得られる。
  \end{enumerate}
  最大で$3m$の預金が得られており、各分割・併合・借用は預金を2支払うので、最大$3m/2$回の分割・併合・借用が実行される。
  ~\figref{btree-split}、\figref{btree-borrow}、\figref{btree-merge}では預金は \cent\ で表した。

  預金の値を追うために、証明では次の\emph{預金不変条件}を保つ。
  \ejindex{credit invariant}{くれじっとふへんじょうけん@預金不変条件}%
  $B-1$個のキーを持つ任意の根でないノードは預金を1だけ持つ。
  $2B-1$個のキーを持つノードは預金を3だけ持つ。
  $B$以上$2B-2$以下のキーを持つノードは預金を持たない。
  あとは、各#add(x)#・#remove(x)#の間に、預金不変条件を保つことと、上で説明した性質1・2を満たすこととを示す。

  \paragraph{追加の場合}
  #add(x)#は併合や借用を行わないため、分割だけを考えれば十分である。

  既に$2B-1$個のキーを持つノード#u#にキーを追加すると分割が発生する。
  この場合、#u#はふたつのノード#u'#と#u''#に分割され、それぞれは$B-1$個、$B$個のキーを持つ。
  直前には#u#が$2B-1$個のキーを持っていたので預金は3あった。
  そのうちの2は分割のために支払われ、あと1は#u'#（$B-1$個のキーを持つ）に渡されるので、預金不変条件が保たれる。
  よって、いかなる分割においても、その分割のための預金を支払える上に、預金不変条件を保てる。

  #add(x)#を実行するとき、ノードに対する他の修正は、すべての分割処理を終えたあと実行される。
  これは新たなキーをあるノード#u'#に追加する処理である。

  直前に#u'#が$2B-2$個の子を持っていれば、子の数は$2B-1$になるので、預金を3得ることになる。これは高々#add(x)#によって得られることになっている預金の範囲内である。

  \paragraph{削除の場合}
  #remove(x)#の際には、0回以上の併合と、それに続く借用が一度発生するかもしれない。
  併合のシナリオとしては、ふたつの#v#と#w#がともに$B-1$個のキーを#remove(x)#を呼ぶ直前に持っており、これらが$2B-2$個のキーをもつひとつのノードに併合されるというものである。
  そのため、併合のために2の預金が支払われている。

  併合のあとには、高々一度の借用処理があり、その後にはもう併合も借用も発生しない。
  この借用が起きるのは、$B-1$個のキーを持つ葉#v#からキーを削除する場合に限る。
  このとき#v#は預金を1持っており、この預金は借用のコストとして使われる。
  しかし、借用のコストは2なので、預金が1足らず、支払いを完了するために預金をあと1必要である。

  ここまでで、預金を1得ており、預金不変条件が保たれていることを示す必要がある。
  最悪の場合には#v#の兄弟#w#が、借用の前にちょうど$B$個のキーを持っていて、直後には#v#も#w#も$B-1$個のキーを持つことになる。
  これは操作が完了するとき、#v#と#w#が預金を1持っている必要があることを意味する。
  よってこの場合には#v#と#w#とに渡すための追加の預金を2作る必要がある。
  借用は#remove(x)#の処理の間に高々一回発生するので、場合に応じて最大で3の預金が作られることがわかった。

  もし#remove(x)# において借用がないなら、これはあるノードでキーを削除して終了したためであり、このノードは操作の前には$B$個以上のキーを持っていたことになる。
  最悪の場合には、このノードがちょうど$B$個のキーを持っており、そのため操作の後では$B-1$個のキーを持ち、預金を1作って与えなければならない。

  削除が借用で終わる場合、そうでない場合のいずれにおいても、預金不変条件を保ち、併合と借用のコストを支払うためには、高々3の預金を#remove(x)#の間に作る必要がある。
  以上より定理が示された。
\end{proof}

\lemref{btree-split}の目的は、ワードRAMモデルにおいて、#add(x)#・#remove(x)#からなる$m$個の操作の列を順に実行するとき、分割・併合・借用にかかる時間は合わせて$O(Bm)$であることを示すことであった。
つまり、これらの操作の償却コストは$O(B)$であり、ワードRAMモデルにおける#add(x)#・#remove(x)#の償却コストは$O(B+\log #n#)$である。
この結果を次のふたつの定理にまとめる。

\begin{thm}[外部メモリモデルにおける$B$木]
#BTree#は#SSet#インターフェースを実装する。
#BTree#は#add(x)#・#remove(x)#・#find(x)#をサポートし、外部メモリモデルではいずれの実行時間も$O(\log_B #n#)$である。
\end{thm}

\begin{thm}[ワードRAMモデルにおける$B$木]
#BTree#は#SSet#インターフェースを実装する。
#BTree#は#add(x)#・#remove(x)#・#find(x)#をサポートする。ワードRAMモデルでは、分割・併合・借用のコストを無視すると、いずれの実行時間も$O(\log_B #n#)$である。
さらに、空の#BTree#に対して、#add(x)#・#remove(x)#からなる$m$個の操作の列を順に実行するとき、分割・併合・借用のためにかかる時間は合わせて$O(Bm)$である。
\end{thm}

\section{ディスカッションと練習問題}

外部メモリモデルを提案したのはAggarwalとVitter\cite{av88}である。
このモデルは\emph{I/Oモデル}
\ejindex{I/O model}{I/Oモデル}%
や\emph{ディスクアクセスモデル}と呼ばれることもある。
\ejindex{disk access model}{でぃすくあくせすもでる@ディスクアクセスモデル}%

内部メモリを使った探索における二分探索木を、外部メモリの場合に拡張したものが$B$木である。
$B$木はMcCreight \cite{bm70}が1970年に提案した。
10年を待たずしてComerのサーベイ（論文のタイトルが"The Ubiquitous B-Tree"）が出版され、その中で$B$木は「このデータ構造はいたるところで使われている」と紹介された。
\cite{c79}

二分探索木と同様に、$B$木には多くの種類がある。
例えば、$B^+$木、
\ejindex{B+-tree@$B^+$-tree}{B+ぎ@$B^+$木}%
$B^*$木、
\ejindex{B*-tree@$B^*$-tree}{B*ぎ@$B^*$木}%
counted $B$木などである。
\index{counted $B$-tree}%
$B$木は本当にいたるところで使われていて、多くのファイルシステムにおける基本的なデータ構造である。
例えば、
AppleのHFS+、
\index{HFS+}%
MicrosoftのNTFS、
\index{NTFS}%
LinuxのExt4などの例がある。
\index{Ext4}%
また、すべてのメジャーなデータベースシステムもそうである。
クラウドコンピューティングで使われているキーバリューストアにもいくつも例がある。
Graefeの近年のサーベイ\cite{g10}では200ページ以上にわたって現代の応用やデータ構造の変種、$B$の最適化などが述べられている。

$B$は#SSet#インターフェースを実装する。
もし#USet#インターフェースだけが必要なときには、外部メモリハッシュ法を$B$木の代わりに使うこともできるだろう。
\ejindex{external memory hashing}{がいぶめもりはっしゅほう@外部メモリハッシュ法}%
外部メモリハッシュ法も広く研究されている。
例えばJensenとPaghの論文\cite{jp08}を見てほしい。
この手法では、外部メモリモデルにおいて$O(1)$の期待実行時間で#USet#の操作を実行できる。
しかし、いくつかの理由で、多くのアプリケーションでは#USet#の操作だけが必要だとしても$B$木を使う。

$B$木が人気がある理由のひとつに、$O(\log_B #n#)$という実行時間の上界から受ける印象より実際には性能がよいことがしばしばあることを挙げられる。
外部メモリモデルでは、$B$の値はふつうかなり大きく、数百あるいは数千である。
そのため、$B$木におけるデータのうち、99\%あるいは99.9\%は葉に保存されている。
大きなメモリを持つデータベースシステムでは、内部ノードはすべてのデータのうちの1\%あるいは0.1\%程度なので、すべてRAMにキャッシュできるかもしれない。
この場合$B$木の検索では、RAM上にある内部ノードの検索はすべて非常に高速に処理でき、一回だけの外部メモリアクセスで葉が得られる。

\begin{exc}
  \figref{btree}の$B$木に1.5、7.5を順に追加するときの様子を描け。
\end{exc}

\begin{exc}
  \figref{btree}の$B$木から3、4を順に削除するときの様子を描け。
\end{exc}

\begin{exc}
#n#個のキーを格納する$B$木の内部ノードの数の最大値を求めよ。（これは#n#と$B$の関数である。）
\end{exc}

\begin{exc}
この章のはじめに、$B$木の内部メモリとして必要なのは$O(B+\log_B#n#)$だけであると言った。
しかし、ここで示した実装では実はより多くのメモリが必要であった。
  \begin{enumerate}
    \item この章で示した#add(x)#・#remove(x)#の実装は$B\log_B #n#$に比例する内部メモリを使うことを示せ。
    \item これを$O(B + \log_B #n#)$に減らすための修正方法を説明せよ。
  \end{enumerate}
\end{exc}

\begin{exc}
  \lemref{btree-split}の証明で使った預金の様子を、図\ref{fig:btree-add}と図\ref{fig:btree-remove-full}の木に描け。
  また、（追加の預金3で）分割・併合・借用のコストを支払い、預金不変条件を保てることを確認せよ。
\end{exc}

\begin{exc}
$B$木を修正し、ノードの持つ子の数が$B$以上$3B$以下（そのため、キーの数は$B-1$以上$3B-1$以下）のデータ構造を設計せよ。
また、この新$B$木では、$m$回の操作を順に実行する間に、$O(m/B)$回だけの分割・併合・借用を実行することを示せ。
（ヒント：これを実現するには、併合処理をもっと頑張らなければならない。必ずしも必要でないときにも、併合を行わなければならないことがある。）
\end{exc}

\begin{exc}
この練習問題では、$B$木の分割・併合を修正し、最大3つのノードを一度に考慮することで、分割・借用・併合処理の漸近的な実行回数を減らす。
  \begin{enumerate}
    \item #u#を一杯になったノード、#v#を#u#のすぐ右の兄弟とする。
	#u#のノード溢れを解消する方法は二通りある。
    \begin{enumerate}
       \item #u#のキーをいくつか#v#に渡す。
       \item #u#を分割し、#u#と#v#のキーを平等に#u#と#v#と新しいノード#w#とで分け合う。
    \end{enumerate}
	この操作のあと、ある定数$\alpha > 0$について、関連する（最大3つの）ノードはいずれも$B+\alpha B$個以上$2B-\alpha B$個以下のキーを持つようにできることを示せ。
    \item ノード#u#はアンダーフローしており、#v#と#w#はの兄弟であるとする。
	#u#のアンダーフローを解消する方法は二通りある。
    \begin{enumerate}
       \item キーを#u#・#v#・#w#の間で分配しなおす。
       \item #u#・#v#・#w#を併合し、ふたつのノードにする。それぞれの持っていたキーはふたつのノードに分配しなおす。
    \end{enumerate}
	この操作のあと、ある定数$\alpha > 0$について、関連する（最大3つの）ノードはいずれも$B+\alpha B$個以上$2B-\alpha B$個以下のキーを持つようにできることを示せ。
    \item 以上の修正によって、$m$回の操作を実行する間に発生する併合・借用・分割の回数は$O(m/B)$になることを示せ。
  \end{enumerate}
\end{exc}


\begin{exc}
  \figref{bplustree}に示した$B^+$木は、すべてのキーを葉に格納し、すべての葉を双方向連結リストとして格納する。
  葉はそれぞれ、ふつう$B-1$個以上$2B-1$個以下のキーを格納する。
  葉から上側はふつうの$B$木で、最後のもの以外の各葉の最大値を内部ノードは蓄えている。
  \begin{enumerate}
    \item $B^+$木における#add(x)#・#remove(x)#・#find(x)#の高速な実装を説明せよ。
    \item #findRange(x,y)#の効率的な実装方法を説明せよ。
	これは$B^+$木に含まれる#x#より大きく#y#より小さいをすべて報告するメソッドである。
    \item #find(x)#・#add(x)#・#remove(x)#・#findRange(x,y)#を持つ、クラス#BPlusTree#を実装せよ。
      \index{BPlusTree@#BPlusTree#}%
    \item $B^+$木では$B$木の部分と、リストの部分の両方に同じキーを格納するため、キーの重複がある。
	$B$の値が大きい時、この重複が大して問題とならない理由を説明せよ。
  \end{enumerate}
\end{exc}

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/bplustree}}
  \caption{$B^+$木は、ブロックの双方向連結リストの上に$B$木が乗ったデータ構造である。}
  \figlabel{bplustree}
\end{figure}
