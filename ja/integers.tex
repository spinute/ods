\chapter{整数を扱うデータ構造}

この章では再び#SSet#の実装を扱う。
ただしここでは、#w#ビットの整数の集まりを表すことに特化した#SSet#を紹介する。
すなわち$#x#\in\{0,\ldots,2^{#w#}-1\}$だと仮定し、#add(x)#、#remove(x)#、#find(x)#を実装する。
整数のデータや整数のキーを扱う場面が多岐に渡るのは想像に難くないだろう。

この章では以上のことをふまえた3つのデータ構造を説明する。
1つ目は#BinaryTrie#であり、このデータ構造は#SSet#の3つの操作をいずれも$O(#w#)$の時間で実行できる。
この実行時間はさして驚くようなものではないだろう。
$\{0,\ldots,2^{#w#}-1\}$の部分集合の大きさ#n#は$#n#\le 2^{#w#}$であり、$\log #n# \le #w#$が成り立つからだ。
この本でこれまで解説した#SSet#の実装では、各操作の実行時間は$O(\log #n#)$であった。
すなわち、いずれも#BinaryTrie#と同じくらいには高速であった。

二つ目は#XFastTrie#であり、このデータ構造は#BinaryTrie#の検索をハッシュ法を使って高速化するものである。
この高速化により、#find(x)#の実行時間が$O(\log #w#)$になる。
しかし#XFastTrie#における#add(x)#と#remove(x)#の実行時間は依然として$O(#w#)$であり、領域使用量は$O(#n#\cdot#w#)$である。

三つ目は#YFastTrie#であり、このデータ構造はおよそ$#w#$個ごとにひとつの要素だけを#XFastTrie#に、それ以外の要素をふつうの#SSet#に格納するデータ構造である。
この工夫により#add(x)#と#remove(x)#の実行時間は$O(\log #w#)$になり、領域使用量は$O(#n#)$に抑えられる。

この章の実装は、整数と対応付けられる任意の型のデータを格納できる。
サンプルコードにおいて、#ix#は#x#に対応する整数を表し、#intValue(x)#は#x#を#ix#に変換する関数とする。
また簡単のため、文中では#x#を整数として扱う。

\section{#BinaryTrie#：デジタル探索木} % TODO: YJ 日本語の「デジタル」は二進数、離散変数という意味はある？ spinute: あると思う（というか、そういう意味だと思っている）。
\seclabel{binarytrie}

\ejindex{BinaryTrie@#BinaryTrie#}{にぶんとらい@二分トライ}%
#BinaryTrie#は#w#ビット整数の集合を二分木で符号化したものである。 % YJ encode=符号化、翻訳、エンコード
この木では、葉の深さはいずれも#w#で、根から葉への経路がある整数を表している。
整数#x#への経路は、深さ#i#において、上から#i#番目のビットが0なら左、1なら右に向かう。
\figref{binarytrie-ex}は$#w#=4$の場合の例を示しており、ここでは整数3(0011), 9(1001), 12(1100), 13(1101)が二分トライに格納されている。 % YJ trie=トライ
\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/binarytrie-ex-1}
  \end{center}
  \caption{二分トライでは、整数を根から葉への経路として符号化する。}
  \figlabel{binarytrie-ex}
\end{figure}

#x#の探索経路は#x#の二進数表記から決まるので、ノード#u#の子を指すポインタを#u.child[0]# (#left#), #u.child[1]# (#right#)と書くと便利である。
葉ではこのポインタを別の用途に使う。
葉には子がいないので、このポインタを使って葉の双方向連結リストを作る。
すなわち、二分トライの葉では、#u.child[0]# (#prev#)はリストにおける#u#の直前のノードを指し、#u.child[1]# (#next#)はリストにおける#u#の直後のノードを指す。
特別なノード#dummy#は先頭のノードの前のノード、および末尾のノードの後のノードである。
（\secref{dllist}を参照せよ。）
\cpponly{サンプルコードでは、#u.child[0]#、#u.left#、#u.prev# はいずれもノード#u#の同じフィールドを参照している。#u.child[1]#、#u.right#、#u.next#も同様である。}

各ノード#u#はポインタ#u.jump#も保持している。
#u#が左の子を持たないとき、#u.jump#は#u#を根とする部分木における最小の葉を指す。
#u#が右の子を持たないとき、#u.jump#は#u#を根とする部分木における最大の葉を指す。
#BinaryTrie#の#jump#ポインタと葉の双方向連結リストとを描いた例が\figref{binarytrie-ex2}である。

\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/binarytrie-ex-2}
  \end{center}
  \caption{二分トライにおける#jump#ポインタを破線の矢印で、リストのリンクを実線の矢印で表す。}
  \figlabel{binarytrie-ex2}
\end{figure}

% XXX: コメントアウトしてあるのはなぜか？
%\jxavaimport{ods/BinaryTrie.Node<Node}
%\cxppimport{ods/BinaryTrie.BinaryTrieNode<Node}

#BinaryTrie#における#find(x)#は簡単だ。
#x#の探索経路を辿ればよい。
葉に辿り着いたら、#x#が存在することがわかる。
（進みたい方向の子がいないため）それ以上進めないノード#u#に辿り着いたときは、#u.jump#を辿る。
そうすると、#x#より大きい最小の葉、または#x#より小さい最大の葉が見つかる。
このどちらになるかは、#u#が左右どちらの子がいないのかに応じて決まる。
#u#が左の子を持たないなら、欲しいノードを見つけたことになる。 % YJ 訳注でfind(x)がx以下の最もxに近い要素を返す関数であることを再確認する？
%% spinute: 訳注を入れました
\footnote{訳注：1章で定義したように、#SSet#の#find(x)#は#x#以上の最小の要素を見つける操作である。}
#u#が右の子を持たないなら、連結リストを辿れば欲しいノードが見つかる。
\figref{binarytrie-find}にはこのふたつの場合を描いた。
\codeimport{ods/BinaryTrie.find(x)}
\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/binarytrie-ex-3}
  \end{center}
  \caption{#find(5)#および#find(8)#が辿る経路}
  \figlabel{binarytrie-find}
\end{figure}
#find(x)#の実行時間において支配的なのは、根から葉への経路を辿る処理であり、この時間は$O(#w#)$である。

#BinaryTrie#における#add(x)#も単純だが、その手順は長い。
\begin{enumerate}
  \item #x#の探索経路を辿り、それ以上進めないノード#u#を見つける。
  \item #u#から#x#を含む葉への、探索経路に足りない部分を作る。
  \item #x#を含むノード#u'#を葉の連結リストに追加する。
  （#u#の#jump#ポインタを使って、連結リストにおける#u'#の直前のノード#pred#を得られる。）
  \item これまで来た経路を戻りながら、#x#を指すべき#jump#ポインタを更新する。
\end{enumerate}
\figref{binarytrie-add}に要素を追加する様子を示した。
\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/binarytrie-add}
  \end{center}
  \caption{\figref{binarytrie-ex2}の#BinaryTrie#に、値2、値15を追加する。}
  \figlabel{binarytrie-add}
\end{figure}
\codeimport{ods/BinaryTrie.add(x)}
このメソッドはまず#x#の探索経路を辿り、その後に根方向に向かって戻る。
この各ステップは定数時間で実行できるので、#add(x)#の実行時間は$O(#w#)$である。


#remove(x)#は#add(x)#のすることを取り消す。
#add(x)#と同様に手順は長い。
\begin{enumerate}
  \item #x#の探索経路を辿り、#x#を含む葉#u#を見つける。
  \item #u#を双方向連結リストから削除する。
  \item #u#を削除し、#x#の探索経路に含まれない子を持つノード#v#を見つけるまで#x#の探索経路を逆に辿りながら、その過程で訪問したノードを削除する。
  \item #v#から根まで辿りながら、#u#を指していた#jump#があれば更新する。
\end{enumerate}
\figref{binarytrie-remove}に削除の様子を描いた。
\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/binarytrie-remove}
  \end{center}
  \caption{\figref{binarytrie-ex2}の#BinaryTrie#から値9を削除する。}
  \figlabel{binarytrie-remove}
\end{figure}
\codeimport{ods/BinaryTrie.remove(x)}

\begin{thm}
#BinaryTrie#は#w#ビット整数を格納するための#SSet#インターフェースの実装である。
#BinaryTrie#における#add(x)#、#remove(x)#、#find(x)#の実行時間はいずれも$O(#w#)$である。
#n#個の要素を格納する#BinaryTrie#の領域使用量は$O(#n#\cdot#w#)$である。
\end{thm}

% XXX: doubly-logarithmicはlog(log(x))のことだろうか（なんと訳そう） % YJ: 訳はなさそうなのでexplicitにLog-Log時間とか？ % Polylogarithm (多重対数関数)と被る名称は良くない
\section{#XFastTrie#：$log(log n)$時間で検索を行う}
\seclabel{xfast}

\ejindex{XFastTrie@#XFastTrie#}{XFastトライ}%
#BinaryTrie#の性能はパッとしないものであった。
要素数#n#は最大で$2^{#w#}$であり、$\log #n#\le #w#$が成り立つ。
この本で説明してきた比較に基づく#SSet#の実装はいずれも、少なくとも#BinaryTrie#と同じくらいは効率的であり、一方で#BinaryTrie#のように整数しか格納できない制限はなかった。

次は#XFastTrie#を説明する。
これは単なる#BinaryTrie#に加えて、各深さにひとつずつ、合計#w+1#個のハッシュテーブルを置いたものである。
これらのハッシュテーブルを使って、#find(x)#の実行時間を$O(\log #w#)$に改善できる。
#BinaryTrie#における#find(x)#は、#x#の探索経路を辿り、進みたい方向の子を持たないノード#u#を見つければ、ほぼ完了であった。
あとは、#u.jump#を利用して葉#v#にジャンプし、#v#か葉のリストにおける#v#の直前のノードのどちらかを返すだけであった。
深さに関する二分探索によりノード#u#を見つけることで、#XFastTrie#はこの探索処理を高速に行う。
\ejindex{binary search}{にぶんたんさく@二分探索}%

二分探索を行うためには探しているノード#u#が、ある深さ#i#より上にあるのか、#i#またはその下にあるのかを判定する必要がある。
これは#x#の二進表現における上位#i#ビットを見ればわかる。
このビット列によって、根から深さ#i#までの#x#の探索経路が決まる。
例えば、\figref{xfast-path}を見てほしい。
14（二進表現では1110）の探索経路における最後のノード#u#は、深さ2にある$11{\star\star}$とラベル付けられたノードである。
これは深さ3に$111{\star}$とラベル付けられたノードが無いためである。
このように、深さ#i#のノードをみな#i#ビットの整数でラベル付けられる。
すると、探している#u#が深さ#i#、またはそれより下にあるのは、深さ#i#に#x#の上位#i#ビットと一致するラベルを持つノードがあるとき、かつそのときに限る。

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/xfast-path}
  \end{center}
  \caption{ラベル$111\star$を持つノードは存在しないので、14 (1110)の探索経路はラベル$11{\star\star}$を持つノードで終了する。}
  \figlabel{xfast-path}
\end{figure}

#XFastTrie#では、$#i#\in\{0,\ldots,#w#\}$について深さ#i#のすべてのノードを#USet# #t[i]#に格納する。
#USet#はハッシュテーブル（\chapref{hashing}）で実装する。
#USet#を使うと、深さ#i#に#x#の上位#i#ビットと一致するラベルを持つノードがあるかどうかを期待定数時間で判定できる。
具体的には、このノードを次のように見つけられる。
\javaonly{#t[i].find(x>>>(w-i))#}%
\cpponly{#t[i].find(x>>(w-i))#}%
\pcodeonly{#t[i].find(x>>(w-i))#}%

ハッシュテーブル$#t[0]#,\ldots,#t[w]#$によって、二分探索で#u#を見つけられる。
最初は、$0\le #i#< #w#+1$を満たすある深さ#i#に#u#があることを知っている。
まずは$#l#=0$, $#h#=#w#+1$とする。
$#i#=\lfloor (#l+h#)/2\rfloor$として、ハッシュテーブル#t[i]#を繰り返し検索する。
$#t[i]#$が#x#の上位#i#ビットと一致するラベルを持つノードを含むとき、#l=i#とする。
（このとき、#u#は深さ#i#、またはそれよりも下にある。）
そうでなければ、#h=i#とする。
（このとき、#u#は深さ#i#よりも上にある。）
$#h-l#\le 1$になればこの処理を終える。
このとき、#u#は深さ#l#にある。
あとは#u.jump#と葉の双方向連結リストとを使って、#find(x)#の処理を完了する。
\codeimport{ods/XFastTrie.find(x)}
上のメソッドの#while#ループにおける各繰り返しにおいて、#h-l#は約半分になる。
よって、このループを$O(\log #w#)$回繰り返すと#u#が見つかる。
各繰り返しでは一定量の仕事をし、一回だけ#USet#の#find(x)#を呼ぶ。
#USet#における検索の実行時間の期待値は定数である。
残りの処理の実行時間も定数なので、#XFastTrie#における#find(x)#の実行時間の期待値は$O(\log#w#)$である。

#XFastTrie#における#add(x)#・#remove(x)#は#BinaryTrie#におけるそれらの操作とほとんど同じである。
修正点はハッシュテーブル#t[0]#,\ldots,#t[w]#を更新することだけである。
#add(x)#の実行中に深さ#i#でノードが作られるとき、このノードを#t[i]#に加える。
#remove(x)#の実行中に深さ#i#でノードが削除されるなら、このノードを#t[i]#から削除する。
ハッシュテーブルにおける追加・削除の実行時間の期待値は定数なので、この修正によって#add(x)#・#remove(x)#の実行時間の期待値は定数程度しか増えない。
#add(x)#・#remove(x)#のコードは、#BinaryTrie#のときに提示した（長い）コードとほぼ同じなので、ここには掲載しない。

次の定理は#XFastTrie#の性能をまとめたものだ。

\begin{thm}
#XFastTrie#は#w#ビット整数の#SSet#インターフェースを実装する。
#XFastTrie#がサポートするのは次の操作である。
\begin{itemize}
\item #add(x)#・#remove(x)#の実行時間の期待値は$O(#w#)$である。
\item #find(x)#の実行時間の期待値は$O(\log #w#)$である。
\end{itemize}
#n#個の要素を格納する#XFastTrie#の領域使用量は$O(#n#\cdot#w#)$である。 % YJ space 領域
\end{thm}

\section{#YFastTrie#：実行時間がDoubly-Logarithmicな#SSet#}
\seclabel{yfast}

#BinaryTrie#と比べると#XFastTrie#における検索の実行時間は指数的に速くなった。
しかし、#add(x)#・#remove(x)#の実行時間は依然として速くない。
さらに、領域使用量は$O(#n#\cdot#w#)$であり、この本で紹介した他の#SSet#の実装の$O(#n#)$と比べて大きい。
このふたつの問題は関連している。
#n#回の#add(x)#によって大きさ$#n#\cdot#w#$の構造を作るなら、#add(x)#の一回あたりの実行時間・領域使用量は#w#程度のオーダーになる。

\ejindex{YFastTrie@#YFastTrie#}{YFastトライ}%
次に紹介する#YFastTrie#は、#XFastTrie#の実行時間と領域使用量を改善する。
#YFastTrie#は#XFastTrie# #xft#を使うが、#xft#には$O(#n#/#w#)$個の値しか入れない。
こうすると#xft#の領域使用量は$O(#n#)$になる。
さらに、#add(x)#・#remove(x)#を#w#回実行するとき、そのうち1回のみ#xft#に#add(x)#・#remove(x)#を実行する。
こうして、#xft#における#add(x)#・#remove(x)#の平均実行時間は定数になる。

きっと疑問を感じるだろう。
#xft#には#n#/#w#個の要素しか格納しないなら、残りの$#n#(1-1/#w#)$個の要素はどこに行くのだろう。
これらの要素は\emph{二次構造}である#Treap#(\secref{treap})を拡張したデータ構造に格納する。
\ejindex{secondary structure}{にじこうぞう@二次構造}%
二次構造は約#n#/#w#個あり、平均的にはそれぞれ$O(#w#)$個の要素を格納する。
Treapは#SSet#の操作を対数時間でサポートするので、各操作の実行時間は期待通り$O(\log #w#)$である。

具体的には、#YFastTrie#は確率$1/#w#$で選り抜いたデータを格納する#XFastTrie# #xft#を保持する。
都合上、#xft#は常に値$2^{#w#}-1$を含むものとする。
また、#xft#が含む要素を$#x#_0<#x#_1<\cdots<#x#_{k-1}$とする。
要素$#x#_i$には対応するTreap $#t#_i$があり、これは$#x#_{i-1}+1,\ldots,#x#_i$の範囲の値をすべて格納する。
\figref{yfast}にこの様子を示す。

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/yfast}
  \end{center}
  \caption{0, 1, 3, 4, 6, 8, 9, 10, 11, 13を含む#YFastTrie#}
  \figlabel{yfast}
\end{figure}

#YFastTrie#における#find(x)#は簡単である。
#x#を#xft#から検索し、Treap $#t#_i$を見つける。
続いて、$#t#_i$の#find(x)#メソッドを使って、問い合わせに答える。
このメソッド全体を一行で書ける。
\codeimport{ods/YFastTrie.find(x)}
はじめの#xft#に対する#find(x)#にかかる時間は$O(\log#w#)$である。
二回目のTreapに対する#find(x)#にかかる時間は$O(\log r)$である。
ここで、$r$はTreapの大きさである。
この節の後半でTreapの大きさの期待値は$O(#w#)$であることを示すので、結局この操作の実行時間は$O(\log #w#)$である。
\footnote{これは\emph{Jensenの不等式}の応用すればよい。$\E[r]=#w#$ならば$\E[\log r] \le \log w$である。}

#YFastTrie#に要素を追加するのも、ほとんどの場合は単純である。
#add(x)#メソッドは#xft.find(x)#を呼んで、#x#を挿入すべきTreap #t#を特定する。
続いて#t.add(x)#を呼んで#x#を#t#に追加する。
ここで確率$1/#w#$で表が、確率$1-1/#w#$で裏が出る、偏りのあるコインを投げる。
もし表が出れば、#x#を#xft#に追加する。

これが少し複雑なところである。
#x#を#xft#に追加するとき、Treap #t#をふたつのTreap #t1#, #t'#に分割しなければならない。
#t1#は#x#以下の値をすべて含む。
#t'#はそれ以外の値を含むように#t#を更新したものである。
最後に、組み#(x,t1)#を#xft#に追加する。
\figref{yfast-add}に例を示す。
\codeimport{ods/YFastTrie.add(x)}
\begin{figure}
  \begin{center}
	% TODO: コードの最後が変: return文が２つ続いている
    \includegraphics[scale=0.90909]{figs/yfast-add}
  \end{center}
  \caption{#YFastTrie#に値2、値6を追加する。6を追加する時のコイン投げで表が出たので、6は#xft#に追加され、$4,5,6,8,9$を含むTreapは分割される。}
  \figlabel{yfast-add}
\end{figure}
#x#を#t#に追加するのにかかる時間は$O(\log #w#)$である。
\excref{treap-split}で、#t#を分割し#t1#と#t'#とを得る処理の実行時間の期待値が$O(\log #w#)$であることを示した。
$(#x#,#t1#)$を#xft#に追加する処理の実行時間は$O(#w#)$だが、これは確率$1/#w#$でのみ起きる。
以上より、#add(x)#の実行時間の期待値は次のようになる。
\[
    O(\log#w#) + \frac{1}{#w#}O(#w#) = O(\log #w#)
\]

#remove(x)#は#add(x)#のしたことを取り消す。
#xft.find(x)#により葉#u#を見つける。
#u#から#x#を含むTreap #t#を得て、#t#から#x#を削除する。
もし#x#が#xft#にも含まれていれば（そして#x#が$2^{#w#}-1$でなければ）、#x#を#xft#から削除し、#x#のTreapの要素をすべてTreap #t2#に追加する。
ここで、#t2#は連結リストにおける#u#の直後のノードに対応するTreapである。
\figref{yfast-remove}にこの様子を示す。
\codeimport{ods/YFastTrie.remove(x)}
\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/yfast-remove}
  \end{center}
  \caption{\figref{yfast-add}の#YFastTrie#から値1、値9を削除する。}
  \figlabel{yfast-remove}
\end{figure}
#xft#からノード#u#を見つけるのに必要な時間の期待値は$O(\log#w#)$である。
#t#から#x#を削除するのにかかる時間の期待値も$O(\log#w#)$である。
繰り返しになるが、\excref{treap-split}では、#t#を分割して#t1#と#t'#とを得る処理の実行時間の期待値も$O(\log #w#)$であることを示した。
#xft#から#x#を削除する必要があるときは、この処理に$O(#w#)$の時間がかかるが、#xft#に#x#が含まれる確率は$1/#w#$である。
よって、#YFastTrie#における削除処理の実行時間の期待値は$O(\log #w#)$である。

この節の前半でこのデータ構造における各Treapの大きさの説明を後回しにしていた。
この章を終える前に、必要な結果を示しておく。

\begin{lem}\lemlabel{yfast-subtreesize}
#x#を#YFastTrie#に格納する整数とし、$#n#_#x#$を#x#を含むTreap #t#の要素数とする。
このとき$\E[#n#_#x#] \le 2#w#-1$が成り立つ。
\end{lem}

\begin{proof}
\figref{yfast-sample}を参照せよ。
$#x#_1<#x#_2<\cdots<#x#_i=#x#<#x#_{i+1}<\cdots<#x#_#n#$を#YFastTrie#の各要素とする。
Treap #t#に含まれる#x#以上の要素を$#x#_i,#x#_{i+1},\ldots,#x#_{i+j-1}$とする。
このうち、#add(x)#の際の偏りのあるコイン投げで表が出たのは$#x#_{i+j-1}$だけである。
つまり、$\E[j]$は偏りのあるコイン投げを表が出るまで繰り返すときの、コイン投げ回数の期待値と等しい。
\footnote{この解析は$j$が$#n#-i+1$を越えることがないことを無視している。しかし、これは$\E[j]$を減らすため、上界に関する性質はやはり成り立つ。}
コイン投げは独立な試行であり、表が出る確率は確率$1/#w#$である。
そのため$\E[j]\le#w#$である。
（$#w#=2$の場合の解析として\lemref{coin-tosses}を参照せよ。）

同様に、#t#の#x#よりも小さい要素$#x#_{i-1},\ldots,#x#_{i-k}$について、これらの$k$回のコイン投げはいずれも裏であり、$#x#_{i-k-1}$のコイン投げは表である。
先の段落と同じく偏りのあるコイン投げを表が出るまで繰り返すときの、裏が出る回数を考えると$\E[k]\le#w#-1$だとわかる。

まとめると、$#n#_#x#=j+k$より、
\[  \E[#n#_#x#] = \E[j+k] = \E[j] + \E[k] \le 2#w#-1 \qedhere \]
\end{proof}
\begin{figure}
  \begin{center}
    \includegraphics[width=\ScaleIfNeeded]{figs/yfast-sample}
  \end{center}
  \caption{#x#を含むtreap #t#の要素数は二回の連続コイン投げ試行により決まる。}
  \figlabel{yfast-sample}
\end{figure}
%Surprisingly, the bound in \lemref{yfast-subtreesize} is tight.  (If this
%isn't surprising to the reader, they can stop reading this paragraph now.)
%This is counterintuitive because #xft# contains any particular element
%with probability $1/#w#$ so it contains about $n/#w#$ elements.  In other
%words, the average number of elements assigned to one treap is #w#.
%\lemref{yfast-subtreesize} says that the expected size of the treap that
%contains #x# is about twice as large as the average.  This seeming
%discrepancy comes from the fact that larger subtrees contain more elements
%and therefore #x# is more likely to be in a larger subtree than a smaller
%one.

\lemref{yfast-subtreesize}が次の定理を示す最後のピースであった。
次の定理は#YFastTrie#の性能をまとめるものである。

\begin{thm}
#YFastTrie#は#w#ビット整数の#SSet#を実装する。
#YFastTrie#は#add(x)#・#remove(x)#・#find(x)#をサポートし、いずれの実行時間の期待値も$O(\log #w#)$である。
#n#要素を格納する#YFastTrie#の領域使用量は$O(#n#+#w#)$である。
\end{thm}

領域使用量における項#w#があるのは#xft#が常に値$2^#w#-1$を格納しているためである。
実装を修正し、この値を格納せずに済ませることも可能だ。
（ただし、いくつか場合分けをコードに追加する必要がある。）
この場合、上の定理における領域使用量は$O(#n#)$になる。

\section{ディスカッションと練習問題}
#add(x)#・#remove(x)#・#find(x)#の実行時間がいずれも$O(\log#w#)$であるデータ構造としてはじめて提案されたのは、van~Emde~Boasによるもので、
\emph{van~Emde~Boas木}
\ejindex{van Emde Boas tree}{van Emde Boasぎ@van Emde Boas木}%
（または\emph{stratified木}）
\ejindex{stratified tree}{stratifiedき@stratified木}%
という名で知られている。\cite{e77}
オリジナルのvan~Emde~Boas木の大きさは$2^{#w#}$で、このために大きな整数についてこのデータ構造は非実用的であった。

#XFastTrie#・#YFastTrie#はWillard \cite{w83}によって提案された。
#XFastTrie#とvan~Emde~Boasには密接な関係がある。
例えば、
#XFastTrie#におけるハッシュテーブルはvan~Emde~Boas木の配列を置き換えたものである。
つまり、ハッシュテーブル#t[i]#に要素を格納する代わりに、van~Emde~Boasでは長さ$2^{#i#}$の配列に要素を格納する。

整数を格納するための他のデータ構造としては、FredmanとWillardのfusion treeがある。\cite{fw93}
\ejindex{fusion tree}{fusionぎ@fusion木}%
このデータ構造は#n#個の#w#ビット整数を$O(#n#)$の領域に格納でき、#find(x)#を$O((\log #n#)/(\log #w#))$の時間で実行できる。
$\log #w# > \sqrt{\log #n#}$ならばfusion treeを、$\log #w# \le \sqrt{\log #n#}$なら#YFastTrie#を使えば、領域使用量$O(#n#)$であり、#find(x)#にかかる時間は$O(\sqrt{\log #n#})$であるデータ構造が得られる。
近年のP\v{a}tra\c{s}cu and Thorup \cite{pt07}が示した下界によると、$O(#n#)$だけの領域を使うデータ構造としては最適である。

\begin{exc}
単純化された#BinaryTrie#を設計・実装せよ。
これは連結リストやジャンプポインタを持たないが、#find(x)#の実行時間は依然として$O(#w#)$である必要がある。
\end{exc}

\begin{exc}
単純化された#XFastTrie#を設計・実装せよ。
これは二分トライを使わない。
代わりに、この実装ではすべてを双方向連結リストと、$#w#+1$個のハッシュテーブルを使って格納する。
\end{exc}

\begin{exc}
#BinaryTrie#は、長さ#w#のビット列を根から葉への経路として表現するデータ構造であると考えられる。
この発想を可変章の文字列を格納する#SSet#の実装に拡張し、#add(s)#・#remove(s)#・#find(s)#をいずれも#s#の長さに比例する時間で実行できるデータ構造を実装せよ。

\noindent ヒント：データ構造の各ノードは文字の値によってインデックスを計算するハッシュテーブルを格納する。
\end{exc}

\begin{exc}
整数$#x#\in\{0,\ldots2^{#w#}-1\}$について、$d(#x#)$を#x#と#find(x)#の返り値との差と定義する。
（なお、#find(x)#が#null#を返すときは、$d(#x#)$は$2^#w#$であるとする。）
例えば、#find(23)#が43を返すとき、$d(23)=20$である。
  \begin{enumerate}
    \item #XFastTrie#における#find(x)#を修正し、実行時間の期待値が$O(1+\log d(#x#))$であるものを設計・実装せよ。
	ヒント：ハッシュテーブル$t[#w#]$は$d(#x#)=0$であるすべての値#x#を格納することで、処理を開始する良い位置を見つけられる。
    \item #XFastTrie#における#find(x)#を修正し、実行時間の期待値が$O(1+\log\log d(#x#))$であるものを設計・実装せよ。
  \end{enumerate}
\end{exc}
