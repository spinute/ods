\chapter{ヒープ}
\chaplabel{heaps}
この章では優先度付きキューの実装を2つ説明する。
いずれも特殊な二分木であり、\emph{ヒープ (heap)}（雑多に積まれた山）と呼ばれている。
\ejindex{heap}{ひーぷ@ヒープ}%
\ejindex{binary heap}{にぶんひーぷ@二分ヒープ}%
\ejindex{heap!binary}{ひーぷ@ヒープ!にぶん@二分}%
これは二分探索木が高度に構造化されながら積み上げられていたのとは対照的である。

ひとつめのヒープの実装は配列を使って完全二分木をシミュレートする。
これを使ってヒープソート（\secref{heapsort}参照）というの整列アルゴリズムを実装できる。
ヒープソートは既知の整列アルゴリズムの中で最速のもののひとつである。
ふたつめに紹介する実装は、より柔軟な二分木である。
この実装では、優先度付きキューの要素すべてを別の優先度付きキューに取り込む操作をサポートする。 % TODO: YJ meld操作は定義されておらず、代わりにmerge操作がある。しかしデータ構造の名前はMeldableHeapなのでどうしたものか。 <- spinute: ここで関数名を見せとくメリットも特になさそうなので、meld は消しました

\section{#BinaryHeap#：非明示的な二分木} % YJ: Implicitは非明示的の方がよいかな
% XXX: この implicit は https://en.wikipedia.org/wiki/Implicit_data_structure のキモチが入っていたりしないか。この意味の implicit には訳語がなさそう
\seclabel{binaryheap}

\index{BinaryHeap@#BinaryHeap#}%
優先度付きキューの最初の実装は400年以上前に発見された手法に基づく。
\emph{Eytzinger法}
\ejindex{Eytzinger's method}{Eytzingerの方法}%
では木のノードを幅優先順（\secref{bintree:traversal}）に配列に入れて完全二分木を表現する。
こうすると、根は0番目、根の左の子は1番目、右の子は2番目、根の左の子の左の子は3番目の位置に格納される。
\figref{eytzinger}を参照せよ。

\begin{figure}
  \begin{center}
    \includegraphics[scale=0.90909]{figs/eytzinger}
  \end{center}
  \caption{Eytzinger法により、配列を使って完全二分木を表現する。}
  \figlabel{eytzinger}
\end{figure}

Eytzinger法を大きな木に適用してみると、規則性が見えてくる。
添え字#i#のノードの左の子の添え字は$#left(i)#=2#i#+1$であり、右の子の添え字は$#right(i)#=2#i#+2$である。
また、添え字#i#のノードの親の添え字は$#parent(i)#=(#i#-1)/2$である。
\codeimport{ods/BinaryHeap.left(i).right(i).parent(i)}

#BinaryHeap#はこの手法を使って完全二分木を非明示的に表現する。
特に、この木の中では要素は\emph{ヒープ順 (heap order)}に並んでいる。
\ejindex{heap-ordered binary tree}{ひーぷじゅんにぶんぎ@ヒープ順二分木}%
\ejindex{binary tree!heap-ordered}{にぶんぎ@二分木!ひーぷじゅん@ヒープ順}%
\ejindex{heap order}{ひーぷじゅん@ヒープ順}%
すなわち、添え字#i#の位置に格納されている値は、#parent(i)#に格納されている値以上である。（ただし、$#i#=0$である根は除く。）
このとき、優先度付き#Queue#における最小値が0番目の位置（根）に格納されていることがわかる。

#BinaryHeap#では#n#個の要素が配列#a#に格納されている。
\codeimport{ods/BinaryHeap.a.n}

#add(x)#の実装は簡単である。
他の配列ベースのデータ構造と同じく、まずは#a#が一杯かどうかを確認する。
（$#a.length#=#n#$かどうかを確認する。）
もしそうなら#a#を拡張する。
続いて#x#を#a[n]#に入れ、#n#を1増やす。
あとはヒープ性（要素がヒープ順に並んでいること）を保てばよい。 % YJ: ヒープ性はヒープ順が保たれていること？ <- spinute: 少し上で定義しているヒープ順に要素が並んでいることが、heap property を満たしていることと同じ意味なのだと思います
これは#x#とその親とを交換する操作を、#x#が親以上になるまで繰り返せばよい。
\figref{heap-insert}を参照せよ。
\codeimport{ods/BinaryHeap.add(x).bubbleUp(i)}

\begin{figure}
  \begin{center}
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-1} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-2} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-3} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-insert-4} \\
  \end{center}
  \caption{#BinaryHeap#に値6を追加する。}
  \figlabel{heap-insert}
\end{figure}

#remove()#はヒープから最小の値を削除するが、この実装にはすこし工夫が必要だ。
根が最小値なのはわかっているが、これを削除したあとにもヒープ性が成り立つことを保証しなければならない。

もっとも簡単な方法は根と#a[n-1]#を交換し、交換後に#a[n-1]#にある値を削除し、#n#を1小さくすることだ。
しかし、その結果新たな根はおそらく最小値ではなくなっている。
そのためこれを下方向に動かす必要がある。
このため、この要素を子供と比較することを繰り返す。
もしこの要素が三つ（自分と子供達）のうち最小ならば処理を終了する。
そうでないなら、子供達のうち小さいものと、この要素とを入れ替え、処理を繰り返す。
\codeimport{ods/BinaryHeap.remove().trickleDown(i)}

\begin{figure}
  \begin{center}
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-1} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-2} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-3} \\
    \includegraphics[height=\QuarterHeightScaleIfNeeded]{figs/heap-remove-4} \\
  \end{center}
  \caption{#BinaryHeap#から最小の値4を削除する。}
  \figlabel{heap-remove}
\end{figure}

他の配列ベースのデータ構造と同様に、#resize()#のための時間を無視する。
この実行時間は\lemref{arraystack-amortized}の償却解析によってわかる。
すると、#add(x)#・#remove()#の実行時間は（非明示の）二分木の高さに依存する。
嬉しいことに、これは\emph{完全}二分木 (complete binary tree)である。
\ejindex{binary tree!complete}{にぶんぎ@二分木!かんぜん@完全}%
\ejindex{complete binary tree}{かんぜんにぶんぎ@完全二分木}%
最大の深さを除く各深さには、可能な最大数のノードがある。 % levelの良い訳語はあるか？
よって、$h$を木の高さとすると、少なくとも$2^h$個のノードがある。
言い換えると、次の式が成り立つ。
\[
  #n# \ge 2^h
\]
両辺の対数を取ると、次の式が成り立つ。
\[
   h \le \log #n#
\]
以上より、#add(x)#・#remove()#のいずれの実行時間も$O(\log #n#)$である。

\subsection{要約}

次の定理は#BinaryHeap#の性能をまとめたものだ。

\begin{thm}\thmlabel{binaryheap}
  #BinaryHeap#は（優先度付き）#Queue#インターフェースの実装である。
  #BinaryHeap#は#add(x)#・#remove()#をサポートし、#resize()#のコストを無視すると、いずれの実行時間も$O(\log #n#)$である。

  空の#BinaryHeap#から任意の$m$個の#add(x)#・#remove()#からなる操作の列を実行する。このときすべての#resize()#にかかる時間の合計は$O(m)$である。
\end{thm}

\section{#MeldableHeap#：ランダムなMeldableヒープ}
\seclabel{meldableheap}
% XXX: meldableは定訳がある? % YJ: Introduction to Algorithmsにあるので日本語版を確認すればあるはず

\index{MeldableHeap@#MeldableHeap#}%
この節では、#MeldableHeap#を紹介する。
これは優先度付き#Queue#の実装で、背後にある構造もまたヒープであるものである。
しかし、#BinaryHeap#のようには要素数から二分木の形が一意には決まらず、#MeldableHeap#における背後にある二分木の形状には制約がない。

#MeldableHeap#における#add(x)#・#remove()#は#merge(h1,h2)#を使って実装される。
この操作は、ヒープのノード#h1#と#h2#を引数とし、#h1#、#h2#を根とする部分木のすべてのノードを含むヒープの根を返す。

#merge(h1,h2)#は再帰的に定義できる。
\figref{meldable-merge}を参照せよ。
#h1#または#h2#が#nil#なら、単に#h2#, #h1#をそれぞれ返せばよい。
そうでないとき、$#h1.x# \le #h2.x#$として一般性を失わない。
このとき新たなヒープの根の値は#h1.x#である。
続いて、#h2#を#h1.left#か#h1.right#のどちらかと再帰的に併合する。
ここでランダム性の出番だ。
コインを投げ、#h2#を#h1.left#と#h1.right#のどちらと併合するかを決める。
\codeimport{ods/MeldableHeap.merge(h1,h2)}

\begin{figure}
  \centering{\includegraphics[width=\ScaleIfNeeded]{figs/meldable-merge}}
  \caption{#h1#と#h2#を併合するために、#h1.left#または#h1.right#のいずれかに#h2#を併合する。}
  \figlabel{meldable-merge}
\end{figure}

次の節では#merge(h1,h2)#の実行時間の期待値が$O(\log #n#)$であることを示す。
ここで、#n#は#h1#と#h2#の要素数の合計である。

#merge(h1,h2)#を使えば、#add(x)#は簡単である。
#x#を含む新たなノード#u#を作り、#u#をヒープの根と併合すればよい。
\codeimport{ods/MeldableHeap.add(x)}
このとき実行時間の期待値は$O(\log (#n#+1)) = O(\log #n#)$である。

#remove()#も同様に簡単である。
削除したいのは根なので、そのふたつの子を併合し、その結果を新たな根とすればよい。
\codeimport{ods/MeldableHeap.remove()}
このときも実行時間の期待値は$O(\log #n#)$である。

実行時間の期待値が$O(\log #n#)$である#MeldableHeap#の操作は他にもいくつかある。
例えば次のものである。
\begin{itemize}
\item #remove(u)#：ヒープからノード#u#を削除する
\item #absorb(h)#：このヒープに#h#の要素をすべて追加し、#h#を空にする % TODO: YJ これはmeld(h)? -- spinute: 章冒頭の記述にあった meld(h) のことなら、meld は absorb ではなく merge の書き間違いで、absorb とは関係ないのでははないでしょうか。僕はこのままであっているのではないかと思っています
\end{itemize}
いずれの操作も定数回だけの#merge(h1,h2)#を使って実装できる。

\subsection{#merge(h1,h2)#の解析}

#merge(h1,h2)#の解析は二分木のランダムウォークに基づく。
二分木の\emph{ランダムウォーク}は根から始まる。
各ステップではコインを投げ、その結果に応じて今のノードから右の子か左の子に進む。
木からはみ出ると処理を終了する。（これは進んだ先が#nil#であったときである。）

次の補題は注目に値する。
この補題は二分木の形状に関わらず成り立つ。

\begin{lem}\lemlabel{tree-random-walk}
#n#個のノードからなる二分木におけるランダムウォークの長さの期待値は#\log (n+1)#以下である。
\end{lem}

\begin{proof}
#n#に関する帰納法により証明する。
$#n#=0$のとき、ステップ数は$0=\log (#n#+1)$である。
以下では、任意の非負整数$#n#'< #n#$について、示したい補題が成り立つと仮定する。

$#n#_1$を左の部分木の大きさとする。
このとき、$#n#_2=#n#-#n#_1-1$が右の部分木の大きさである。
根からはじめて、一歩進み、大きさ$#n#_1$または$#n#_2$の部分木について処理を続ける。
仮定より、ステップ数の期待値は次のようになる。
% XXX: 原著では等号になっているが、仮定は不等号ではないか
\[
    \E[W] \le 1 + \frac{1}{2}\log (#n#_1+1) + \frac{1}{2}\log (#n#_2+1)
\]
これは$#n#_1$と$#n#_2$はいずれも$#n#$より小さいためである。
$\log$は凹関数（上に凸な関数）なので、$\E[W]$は$#n#_1=#n#_2=(#n#-1)/2$で最大値を取る。
よって、ランダムウォークのステップ数の期待値は次のようになる。
\begin{align*}
    \E[W]
% XXX: ここも上と同様（原著では等号になっている）
   & \le 1 + \frac{1}{2}\log (#n#_1+1) + \frac{1}{2}\log (#n#_2+1) \\
   & \le  1 + \log ((#n#-1)/2+1) \\
   & =  1 + \log ((#n#+1)/2) \\
   & =  \log (#n#+1)  \enspace \qedhere
\end{align*}
\end{proof}

余談だが、情報理論について知っている読者は\lemref{tree-random-walk}の証明をエントロピーの用語で言い換えることができるだろう。
\begin{proof}[\lemref{tree-random-walk}の情報理論的な証明]
$d_i$を$i$番目の外部ノード(#nil#)の深さとする。
#n#個のノードを持つ二分木は#n+1#個の外部ノードを持つことを思い出そう。
ランダムウォークが$i$番目の外部ノードにたどり着く確率は$p_i=1/2^{d_i}$である。
よってランダムウォークのステップ数の期待値は次のように計算できる。
\[
   H=\sum_{i=0}^{#n#} p_id_i
    =\sum_{i=0}^{#n#} p_i\log\left(2^{d_i}\right)
    = \sum_{i=0}^{#n#}p_i\log({1/p_i})
\]
右辺は$#n#+1$個の要素に渡って確率分布のエントロピーを求めたものだとわかるだろう。
$#n#+1$個の要素にわたる分布のエントロピーに関する基本的な事実として、これはこの値は$\log(#n#+1)$を超えない。
よって補題が示された。
\end{proof}

ランダムウォークに関するこの結果より、#merge(h1,h2)#の実行時間の期待値は$O(\log #n#)$であることを示せる。

\begin{lem}
  #h1#・#h2#はふたつのヒープの根であり、それぞれのヒープは$#n#_1$, $#n#_2$個のノードを含むとする。
  このとき、#merge(h1,h2)#の実行時間は$O(\log #n#)$以下である。
  ただし、ここで$#n#=#n#_1+#n#_2$である。
\end{lem}

\begin{proof}
#merge#の各ステップはランダムウォークを1ステップで、#h1#か#h2#のいずれかを根とする部分木に進む。
このアルゴリズムはふたつのランダムウォークのどちらかが木からはみ出すと終了する。
（これは$#h1#=#null#$または$#h2#=#null#$のときである。）
よって、併合アルゴリズムのステップ数の期待値は次の値以下である。
  \[
     \log (#n#_1+1) + \log (#n#_2+1) \le 2\log #n# \qedhere
  \]
\end{proof}

\subsection{要約}

次の定理は#MeldableHeap#をまとめるものである。

\begin{thm}\thmlabel{meldableheap}
  #MeldableHeap#は優先度付き#Queue#インターフェースを実装する。
  #add(x)#・#remove()#をサポートし、いずれの実行時間の期待値も$O(\log #n#)$である。
\end{thm}

\section{ディスカッションと練習問題}

完全二分木を配列またはリストを使って非明示的に表現する方法はEytzinger \cite{e1590}が最初に提案したようである。
彼は貴族の家系図が書いてある本でこれを使った。
\ejindex{pedigree family tree}{かけいず@家系図}%
この章で説明した#BinaryHeap#はWilliams \cite{w64}が最初に提案したものである。

この章で説明したランダム操作を利用した#MeldableHeap#はGambinとMalinowski \cite{gm98}が最初に提案した。
他のMeldable Heapも存在し、
leftist heaps \cite[Section~5.3.2]{c72,k97v3}、
\ejindex{leftist heap}{leftist heap}%
\ejindex{heap!leftist}{ひーぷ@ヒープ!leftist}%
binomial heaps \cite{v78}、
\ejindex{binomial heap}{にこうひーぷ@二項ヒープ}%
\ejindex{heap!binomial}{ひーぷ@ヒープ!にこう@二項}%
Fibonacci heaps \cite{ft87}、
\ejindex{Fibonacci heap}{ふぃぼなっちひーぷ@フィボナッチヒープ}%
\ejindex{heap!Fibonacci}{ひーぷ@ヒープ!ふぃぼなっち@フィボナッチ}%
pairing heaps \cite{fsst86}、
\ejindex{pairing heap}{pairing heap}%
\ejindex{heap!pairing}{ひーぷ@ヒープ!pairing}%
skew heaps \cite{st83}などがある。
\ejindex{skew heap}{skew heap}%
\ejindex{heap!skew}{ひーぷ@ヒープ!skew}%
しかし、いずれも#MeldableHeap#ほどシンプルではない。

上のデータ構造の中には#decreaseKey(u,y)#をサポートするものもある。
\index{decreaseKey@#decreaseKey(u,y)#}%
これはノード#u#に格納される値を小さくして#y#とするものである。
（これを実行する前には$#y#\le#u.x#$である必要がある。）
上に挙げたデータ構造の大部分では、ノード#u#を削除し、#y#を追加するので$O(\log #n#)$の時間がかかる。
しかし、一部のデータ構造ではこれをもっと効率的に実装できる。
とくに、Fibonacci heapsでは$O(1)$の償却実行時間で、pairing heaps \cite{e09}の特殊なものでは$O(\log\log #n#)$の償却実行時間でそれぞれ#decreaseKey(u,y)#を実行できる。
効率的な#decreaseKey(u,y)#はグラフアルゴリズムの高速化に役立つ。（例えばダイクストラ法）
\cite{ft87}

\begin{exc}
  \figref{heap-insert}に示した#BinaryHeap#に7, 3を順に追加する様子を図示せよ。
\end{exc}

\begin{exc}
\figref{heap-remove}に示した#BinaryHeap#から次のふたつの値（6と8）を順に削除する様子を図示せよ。
\end{exc}

\begin{exc}
  #remove(i)#を実装せよ。
  これは#BinaryHeap#における#a[i]#の値を削除するメソッドである。
  このメソッドの実行時間は$O(\log #n#)$でなければならない。
  また、なぜこのメソッドが役立ちそうにないかを説明せよ。
\end{exc}

\begin{exc}\exclabel{general-eytzinger}
  \ejindex{tree!$d$-ary}{き@木!$d$-aray}%
  $d$分木は二分木の一般化である。
  これは各内部ノードが$d$個の子を持つ木である。
  Eytzingerの方法を使えば、完全$d$分木も配列を使って表現できる。
  すなわち、添え字#i#が与えられたとき、#i#の親と、#i#の$d$個の子、それぞれの添え字を計算する方法を与えよ。
\end{exc}

\begin{exc}
  \index{DaryHeap@#DaryHeap#}%
  \excref{general-eytzinger}で学んだことを使って\emph{#DaryHeap#}を設計・実装せよ。
  これは$d$分木版の#BinaryHeap#である。
  #DaryHeap#の操作の実行時間を解析し、#DaryHeap#の性能を#BinaryHeap#と比較せよ。
\end{exc}

\begin{exc}
  \figref{meldable-merge}に示した#MeldableHeap#に17, 82を順に追加する様子を図示せよ。
  ランダムなビットが必要なときにはコインを使うこと。
\end{exc}

\begin{exc}
  \figref{meldable-merge}に示した#MeldableHeap#から、次のふたつの値（4と8）を削除せよ。
  ランダムなビットが必要なときにはコインを使うこと。
\end{exc}

\begin{exc}
#MeldableHeap#からノード#u#を削除する#remove(u)#を実装せよ。
ただし、このメソッドの実行時間の期待値は$O(\log #n#)$でなければならない。
\end{exc}

\begin{exc}
#BinaryHeap#・#MeldableHeap#における二番目に小さい値を定数時間で見つける方法を示せ。
\end{exc}

\begin{exc}
#BinaryHeap#・#MeldableHeap#におけるk番目に小さい値を$O(k\log k)$の時間で見つける方法を示せ。
（ヒント：別のヒープを使うといいかもしれない。）
\end{exc}

\begin{exc}
#k#個の整列済みリストであって、合計の長さが#n#であるものがあるとき、ヒープを使ってこれらのリストを一つの整列済みリストにする方法を示せ。
このとき実行時間は$O(n\log k)$でなければならない。
（ヒント：$k=2$の場合から考えてみるのがよいかもしれない。）
\end{exc}
